# ðŸ§  VisionInfantNet

**VisionInfantNet** is a deep learning pipeline for **visual classification of infant vocalizations** using image representations of short audio segments (e.g., Mel-spectrograms).  


---

## ðŸ§¾ Citation

If you use or adapt this repository, please cite:

```
@software{arun_visioninfantnet_2025,
  author       = {Arun Singh},
  title        = {VisionInfantNet: Visual Classification of Infant Vocalizations},
  year         = {2025},
  url          = {https://github.com/arunps12/VisionInfantNet}
}
```

---

## ðŸ“¬ Contact

**Author:** Arun Singh  
**Affiliation:** University of Oslo, Norway  
**Email:** [arunps@uio.no](mailto:arunps@uio.no)  
**Hugging Face Space:** [https://huggingface.co/spaces/arunps/Adult_Infant_voc_test](https://huggingface.co/spaces/arunps/Adult_Infant_voc_test)

---

## ðŸªª License

This project is released under the **MIT License**.  
You are free to use, modify, and distribute it with proper attribution.

---

## ðŸŒŸ About Me

Hi there! I'm **Arun Prakash Singh**, a **Marie Curie Research Fellow at the University of Oslo (UiO)**.  
My research focuses on **speech technology, data engineering, and machine learning**, with an emphasis on building intelligent, data-driven systems that model human communication and learning.  
I am passionate about integrating **AI, analytics, and large-scale data pipelines** to advance our understanding of how humans process and acquire language.
