{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f451bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one level up into project folder\n",
    "import os\n",
    "#os.chdir(\"..\")\n",
    "\n",
    "#print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "818341d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import mlflow\n",
    "import dagshub\n",
    "\n",
    "from visioninfantnet.utils.ml_utils.metric.classification_metric import (\n",
    "    get_classification_score,\n",
    ")\n",
    "from visioninfantnet.exception.exception import VisionInfantNetException\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ad40d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as arunps12\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as arunps12\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"arunps12/VisionInfantNet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"arunps12/VisionInfantNet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository arunps12/VisionInfantNet initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository arunps12/VisionInfantNet initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run receptive-duck-897 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/0/runs/eb73d4a856de40f5afcde1a29d8b3a20\n",
      "üß™ View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "mlflow_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(mlflow_uri)\n",
    "dagshub.init(repo_owner='arunps12', repo_name='VisionInfantNet', mlflow=True)\n",
    "\n",
    "import mlflow\n",
    "with mlflow.start_run():\n",
    "  mlflow.log_param('parameter name', 'value')\n",
    "  mlflow.log_metric('metric name', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24484568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/itf-fi-ml/home/arunps/Projects/VisionInfantNet/artifacts/12_02_2025_10_27_46/data_transformation/spectrograms/train\n",
      "/itf-fi-ml/home/arunps/Projects/VisionInfantNet/artifacts/12_02_2025_10_27_46/data_transformation/spectrograms/valid\n",
      "/itf-fi-ml/home/arunps/Projects/VisionInfantNet/artifacts/12_02_2025_10_27_46/data_transformation/features/train_labels.npy\n",
      "/itf-fi-ml/home/arunps/Projects/VisionInfantNet/artifacts/12_02_2025_10_27_46/data_transformation/features/valid_labels.npy\n"
     ]
    }
   ],
   "source": [
    "#Paths and data loading helper\n",
    "\n",
    "ARTIFACT_ROOT = os.getenv(\"ARTIFACT_ROOT\")\n",
    "\n",
    "TRAIN_IMG_DIR = os.path.join(ARTIFACT_ROOT, \"data_transformation\", \"spectrograms\", \"train\")\n",
    "VAL_IMG_DIR   = os.path.join(ARTIFACT_ROOT, \"data_transformation\", \"spectrograms\", \"valid\")\n",
    "\n",
    "TRAIN_LABEL_NPY = os.path.join(ARTIFACT_ROOT, \"data_transformation\", \"features\", \"train_labels.npy\")\n",
    "VAL_LABEL_NPY   = os.path.join(ARTIFACT_ROOT, \"data_transformation\", \"features\", \"valid_labels.npy\")\n",
    "\n",
    "print(TRAIN_IMG_DIR)\n",
    "print(VAL_IMG_DIR)\n",
    "print(TRAIN_LABEL_NPY)\n",
    "print(VAL_LABEL_NPY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3778f318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600 3600\n",
      "3580 3580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load labels and image paths\n",
    "train_labels = np.load(TRAIN_LABEL_NPY)\n",
    "val_labels   = np.load(VAL_LABEL_NPY)\n",
    "\n",
    "train_image_paths = sorted(glob.glob(os.path.join(TRAIN_IMG_DIR, \"*.png\")))\n",
    "val_image_paths   = sorted(glob.glob(os.path.join(VAL_IMG_DIR, \"*.png\")))\n",
    "\n",
    "print(len(train_image_paths), len(train_labels))\n",
    "print(len(val_image_paths), len(val_labels))\n",
    "\n",
    "num_classes = len(np.unique(train_labels))\n",
    "num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47b48fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {np.str_('Canonical'): 0, np.str_('Crying'): 1, np.str_('Junk'): 2, np.str_('Laughing'): 3, np.str_('Non-canonical'): 4}\n",
      "num_classes: 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique_labels = sorted(set(train_labels) | set(val_labels))\n",
    "label_to_idx = {lab: i for i, lab in enumerate(unique_labels)}\n",
    "idx_to_label = {i: lab for lab, i in label_to_idx.items()}\n",
    "\n",
    "print(\"Label mapping:\", label_to_idx)\n",
    "num_classes = len(unique_labels)\n",
    "print(\"num_classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e24f1898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "train_labels_idx = np.array([label_to_idx[l] for l in train_labels])\n",
    "val_labels_idx   = np.array([label_to_idx[l] for l in val_labels])\n",
    "print(train_labels_idx[:10])\n",
    "print(val_labels_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb230b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: [ 444  243 1430   46 1437]\n",
      "Class weights (per class): [0.00225225 0.00411523 0.0006993  0.02173913 0.00069589]\n",
      "Sample weights shape: torch.Size([3600])\n",
      "Sample weights (first 10): tensor([0.0041, 0.0041, 0.0041, 0.0041, 0.0041, 0.0041, 0.0041, 0.0041, 0.0041,\n",
      "        0.0041])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# counts per class in TRAIN set\n",
    "class_counts = np.bincount(train_labels_idx, minlength=num_classes)\n",
    "print(\"Class counts:\", class_counts)\n",
    "\n",
    "# inverse-frequency weights ‚Üí higher for minority classes\n",
    "class_weights = 1.0 / (class_counts + 1e-6)\n",
    "print(\"Class weights (per class):\", class_weights)\n",
    "\n",
    "# per-sample weights\n",
    "sample_weights = class_weights[train_labels_idx]     # shape: [num_train_samples]\n",
    "sample_weights_tensor = torch.from_numpy(sample_weights).float()\n",
    "print(\"Sample weights shape:\", sample_weights_tensor.shape)\n",
    "print(\"Sample weights (first 10):\", sample_weights_tensor[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "432ef013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "def _get_ft_axes(spec: torch.Tensor):\n",
    "    \"\"\"\n",
    "    For image/spectrogram tensors shaped [C,H,W] or [H,W].\n",
    "    Treat H as 'freq' and W as 'time'.\n",
    "    \"\"\"\n",
    "    if spec.ndim == 3:   # [C, H, W]\n",
    "        return 1, 2\n",
    "    elif spec.ndim == 2: # [H, W]\n",
    "        return 0, 1\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected tensor shape: {spec.shape}\")\n",
    "\n",
    "def random_time_mask(spec, max_mask_pct=0.1, num_masks=1):\n",
    "    \"\"\"\n",
    "    Mask along the time axis (width).\n",
    "    \"\"\"\n",
    "    F_axis, T_axis = _get_ft_axes(spec)\n",
    "    _, T = (spec.shape[F_axis], spec.shape[T_axis])\n",
    "    out = spec.clone()\n",
    "    max_mask = int(T * max_mask_pct)\n",
    "    if max_mask < 1:\n",
    "        return out\n",
    "    for _ in range(num_masks):\n",
    "        t = random.randint(0, max_mask)\n",
    "        t0 = random.randint(0, max(0, T - t))\n",
    "        idx = torch.arange(t0, t0 + t, device=spec.device)\n",
    "        out.index_fill_(T_axis, idx, 0.0)\n",
    "    return out\n",
    "\n",
    "def random_freq_mask(spec, max_mask_pct=0.1, num_masks=1):\n",
    "    \"\"\"\n",
    "    Mask along the frequency axis (height).\n",
    "    \"\"\"\n",
    "    F_axis, T_axis = _get_ft_axes(spec)\n",
    "    F_dim, _ = (spec.shape[F_axis], spec.shape[T_axis])\n",
    "    out = spec.clone()\n",
    "    max_mask = int(F_dim * max_mask_pct)\n",
    "    if max_mask < 1:\n",
    "        return out\n",
    "    for _ in range(num_masks):\n",
    "        f = random.randint(0, max_mask)\n",
    "        f0 = random.randint(0, max(0, F_dim - f))\n",
    "        idx = torch.arange(f0, f0 + f, device=spec.device)\n",
    "        out.index_fill_(F_axis, idx, 0.0)\n",
    "    return out\n",
    "\n",
    "def random_time_shift(spec, max_shift_pct=0.1):\n",
    "    \"\"\"\n",
    "    Roll along time axis.\n",
    "    \"\"\"\n",
    "    F_axis, T_axis = _get_ft_axes(spec)\n",
    "    _, T = (spec.shape[F_axis], spec.shape[T_axis])\n",
    "    max_shift = int(T * max_shift_pct)\n",
    "    if max_shift < 1:\n",
    "        return spec\n",
    "    shift = random.randint(-max_shift, max_shift)\n",
    "    return torch.roll(spec, shifts=shift, dims=T_axis)\n",
    "\n",
    "def random_gain(spec, min_gain=0.8, max_gain=1.2):\n",
    "    \"\"\"\n",
    "    Multiply tensor by a random gain factor.\n",
    "    \"\"\"\n",
    "    gain = random.uniform(min_gain, max_gain)\n",
    "    return spec * gain\n",
    "\n",
    "def apply_augmentations(spec, label, aug_cfg: dict):\n",
    "    \"\"\"\n",
    "    Apply a combination of augmentations defined in aug_cfg to spec.\n",
    "    \"\"\"\n",
    "    if aug_cfg.get(\"time_mask\", False):\n",
    "        spec = random_time_mask(\n",
    "            spec,\n",
    "            max_mask_pct=aug_cfg.get(\"time_mask_pct\", 0.1),\n",
    "            num_masks=aug_cfg.get(\"time_mask_num\", 1),\n",
    "        )\n",
    "\n",
    "    if aug_cfg.get(\"freq_mask\", False):\n",
    "        spec = random_freq_mask(\n",
    "            spec,\n",
    "            max_mask_pct=aug_cfg.get(\"freq_mask_pct\", 0.1),\n",
    "            num_masks=aug_cfg.get(\"freq_mask_num\", 1),\n",
    "        )\n",
    "\n",
    "    if aug_cfg.get(\"time_shift\", False):\n",
    "        spec = random_time_shift(\n",
    "            spec,\n",
    "            max_shift_pct=aug_cfg.get(\"time_shift_pct\", 0.1),\n",
    "        )\n",
    "\n",
    "    if aug_cfg.get(\"gain\", False):\n",
    "        spec = random_gain(\n",
    "            spec,\n",
    "            min_gain=aug_cfg.get(\"gain_min\", 0.8),\n",
    "            max_gain=aug_cfg.get(\"gain_max\", 1.2),\n",
    "        )\n",
    "\n",
    "    return spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b99998b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "class SpectrogramImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, train: bool = True, aug_cfg: dict = None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.train = train\n",
    "        self.aug_cfg = aug_cfg or {}\n",
    "\n",
    "        base_transforms = [\n",
    "            T.Resize((224, 224)),\n",
    "            T.ToTensor(),              # -> [1, H, W], values [0,1]\n",
    "        ]\n",
    "        self.transforms = T.Compose(base_transforms)\n",
    "\n",
    "        # Normalize to [-1,1] per channel\n",
    "        self.normalize = T.Normalize(\n",
    "            mean=[0.5, 0.5, 0.5],\n",
    "            std=[0.5, 0.5, 0.5],\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        # Load grayscale PNG (0..255)\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "\n",
    "        # Apply transforms ‚Üí [1,224,224] in [0,1]\n",
    "        img = self.transforms(img)\n",
    "\n",
    "        # Convert grayscale -> RGB by repeating channels ‚Üí [3,224,224]\n",
    "        img = img.repeat(3, 1, 1)\n",
    "\n",
    "        # Apply augmentations only for training\n",
    "        if self.train and self.aug_cfg:\n",
    "            img = apply_augmentations(img, label, self.aug_cfg)\n",
    "\n",
    "        # Normalize to [-1,1]\n",
    "        img = self.normalize(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a61b8d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mixup_batch(inputs, labels, alpha=0.4):\n",
    "    \"\"\"\n",
    "    MixUp for one batch.\n",
    "    Returns mixed_inputs, targets_a, targets_b, lam.\n",
    "    \"\"\"\n",
    "    if alpha <= 0:\n",
    "        return inputs, labels, labels, 1.0\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = inputs.size(0)\n",
    "    index = torch.randperm(batch_size, device=inputs.device)\n",
    "\n",
    "    mixed_inputs = lam * inputs + (1 - lam) * inputs[index]\n",
    "    targets_a, targets_b = labels, labels[index]\n",
    "    return mixed_inputs, targets_a, targets_b, lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "131e87b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # downsample by /2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class BaseCNNSpectrogram(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        base_channels: int = 32,\n",
    "        num_blocks: int = 3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        channels = [3] + [base_channels * (2 ** i) for i in range(num_blocks)]\n",
    "        conv_blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            conv_blocks.append(ConvBlock(channels[i], channels[i+1]))\n",
    "        self.conv = nn.Sequential(*conv_blocks)\n",
    "\n",
    "        last_channels = channels[-1]\n",
    "        spatial_size = 224 // (2 ** num_blocks)  # after MaxPool(2) num_blocks times\n",
    "        self.flatten_dim = last_channels * spatial_size * spatial_size\n",
    "\n",
    "        # Single DNN classification layer: Flatten -> Linear -> logits\n",
    "        self.fc = nn.Linear(self.flatten_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f96e6ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "import torch.nn as nn\n",
    "\n",
    "def init_cnn_weights(m, init_method=\"pytorch_default\"):\n",
    "    \"\"\"\n",
    "    Apply chosen initialization method to Conv and Linear layers.\n",
    "    For 'pytorch_default' we do nothing.\n",
    "    \"\"\"\n",
    "    if not isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        return\n",
    "\n",
    "    if init_method == \"pytorch_default\":\n",
    "        return  # keep PyTorch default\n",
    "\n",
    "    if init_method == \"kaiming_normal\":\n",
    "        init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "    elif init_method == \"kaiming_uniform\":\n",
    "        init.kaiming_uniform_(m.weight, nonlinearity=\"relu\")\n",
    "    elif init_method == \"xavier_normal\":\n",
    "        init.xavier_normal_(m.weight)\n",
    "    elif init_method == \"xavier_uniform\":\n",
    "        init.xavier_uniform_(m.weight)\n",
    "\n",
    "    if m.bias is not None:\n",
    "        nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1cf53fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLflow experiment: cnn_exp4_augment_ablation\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 15\n",
    "\n",
    "NUM_BLOCKS = 5\n",
    "BASE_CHANNELS = 64\n",
    "INIT_METHOD = \"pytorch_default\"\n",
    "\n",
    "MLFLOW_EXPERIMENT = \"cnn_exp4_augment_ablation\"\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
    "print(\"Using MLflow experiment:\", MLFLOW_EXPERIMENT)\n",
    "\n",
    "def train_one_cnn_experiment(\n",
    "    num_blocks: int,\n",
    "    base_channels: int,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    num_classes: int,\n",
    "    batch_size: int = 64,\n",
    "    lr: float = 1e-3,\n",
    "    weight_decay: float = 1e-4,\n",
    "    epochs: int = 15,\n",
    "    run_name: str = None,\n",
    "    MODEL_DIR: str = \"saved_models\",\n",
    "    init_method: str = \"pytorch_default\",\n",
    "    use_mixup: bool = False,\n",
    "    mixup_alpha: float = 0.4,\n",
    "    aug_cfg_name: str = \"none\",\n",
    "    use_weighted_sampler: bool = False,\n",
    "    sample_weights: torch.Tensor = None,\n",
    "):\n",
    "    if use_weighted_sampler and sample_weights is not None:\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True,\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=sampler,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    else:\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    model = BaseCNNSpectrogram(\n",
    "        num_classes=num_classes,\n",
    "        base_channels=base_channels,\n",
    "        num_blocks=num_blocks,\n",
    "    ).to(device)\n",
    "\n",
    "    model.apply(lambda m: init_cnn_weights(m, init_method=init_method))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    if run_name is None:\n",
    "        run_name = f\"cnn_blocks{num_blocks}_base{base_channels}_{init_method}_{aug_cfg_name}\"\n",
    "\n",
    "    best_val_uar = 0.0\n",
    "    best_epoch = -1\n",
    "\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_param(\"num_blocks\", num_blocks)\n",
    "        mlflow.log_param(\"base_channels\", base_channels)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "        mlflow.log_param(\"weight_decay\", weight_decay)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"model_type\", \"BaseCNN_flatten_linear\")\n",
    "        mlflow.log_param(\"init_method\", init_method)\n",
    "        mlflow.log_param(\"use_mixup\", use_mixup)\n",
    "        mlflow.log_param(\"mixup_alpha\", mixup_alpha)\n",
    "        mlflow.log_param(\"aug_cfg_name\", aug_cfg_name)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # ----- TRAIN -----\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "\n",
    "            for imgs, labels in train_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if use_mixup:\n",
    "                    imgs_mixed, targets_a, targets_b, lam = mixup_batch(\n",
    "                        imgs, labels, alpha=mixup_alpha\n",
    "                    )\n",
    "                    outputs = model(imgs_mixed)\n",
    "                    loss = lam * criterion(outputs, targets_a) + \\\n",
    "                           (1 - lam) * criterion(outputs, targets_b)\n",
    "                else:\n",
    "                    outputs = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item() * imgs.size(0)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                train_correct += (preds == labels).sum().item()\n",
    "                train_total += labels.size(0)\n",
    "\n",
    "            train_loss /= train_total\n",
    "            train_acc = train_correct / train_total\n",
    "\n",
    "            # ----- VALIDATION -----\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            all_true, all_pred = [], []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for imgs, labels in val_loader:\n",
    "                    imgs = imgs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    val_loss += loss.item() * imgs.size(0)\n",
    "                    preds = outputs.argmax(dim=1)\n",
    "\n",
    "                    val_correct += (preds == labels).sum().item()\n",
    "                    val_total += labels.size(0)\n",
    "\n",
    "                    all_true.extend(labels.cpu().numpy().tolist())\n",
    "                    all_pred.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "            val_loss /= val_total\n",
    "            val_acc = val_correct / val_total\n",
    "\n",
    "            metrics = get_classification_score(\n",
    "                y_true=all_true,\n",
    "                y_pred=all_pred,\n",
    "                average=\"weighted\",\n",
    "            )\n",
    "\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "            mlflow.log_metric(\"train_acc\", train_acc, step=epoch)\n",
    "            mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "            mlflow.log_metric(\"val_acc\", val_acc, step=epoch)\n",
    "            mlflow.log_metric(\"val_f1\", metrics.f1_score, step=epoch)\n",
    "            mlflow.log_metric(\"val_precision\", metrics.precision_score, step=epoch)\n",
    "            mlflow.log_metric(\"val_recall\", metrics.recall_score, step=epoch)\n",
    "            mlflow.log_metric(\"val_uar\", metrics.uar, step=epoch)\n",
    "\n",
    "            if metrics.uar > best_val_uar:\n",
    "                best_val_uar = metrics.uar\n",
    "                best_epoch = epoch\n",
    "                model_path = os.path.join(\n",
    "                    MODEL_DIR,\n",
    "                    f\"best_model_blocks{num_blocks}_base{base_channels}_init_{init_method}_aug_{aug_cfg_name}.pt\"\n",
    "                )\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                mlflow.log_artifact(model_path)\n",
    "\n",
    "            print(\n",
    "                f\"[{run_name}] Epoch {epoch+1}/{epochs} | \"\n",
    "                f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.3f} | \"\n",
    "                f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.3f} | \"\n",
    "                f\"F1: {metrics.f1_score:.3f} UAR: {metrics.uar:.3f}\"\n",
    "            )\n",
    "\n",
    "        mlflow.log_metric(\"best_val_uar\", best_val_uar)\n",
    "        mlflow.log_param(\"best_epoch\", best_epoch)\n",
    "\n",
    "    return model, best_val_uar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a4d71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_AUG_CFG = {\n",
    "    \"time_mask\": True,\n",
    "    \"time_mask_pct\": 0.1,\n",
    "    \"time_mask_num\": 2,\n",
    "    \"freq_mask\": True,\n",
    "    \"freq_mask_pct\": 0.1,\n",
    "    \"freq_mask_num\": 2,\n",
    "    \"time_shift\": True,\n",
    "    \"time_shift_pct\": 0.1,\n",
    "    \"gain\": True,\n",
    "    \"gain_min\": 0.8,\n",
    "    \"gain_max\": 1.2,\n",
    "}\n",
    "\n",
    "AUG_EXPERIMENTS = {\n",
    "    \n",
    "    \"all_aug\": {\n",
    "        \"aug_cfg\": FULL_AUG_CFG,\n",
    "        \"use_mixup\": True,\n",
    "    },\n",
    "    \"no_time_mask\": {\n",
    "        \"aug_cfg\": {**FULL_AUG_CFG, \"time_mask\": False},\n",
    "        \"use_mixup\": True,\n",
    "    },\n",
    "    \"no_freq_mask\": {\n",
    "        \"aug_cfg\": {**FULL_AUG_CFG, \"freq_mask\": False},\n",
    "        \"use_mixup\": True,\n",
    "    },\n",
    "    \"no_time_shift\": {\n",
    "        \"aug_cfg\": {**FULL_AUG_CFG, \"time_shift\": False},\n",
    "        \"use_mixup\": True,\n",
    "    },\n",
    "    \"no_gain\": {\n",
    "        \"aug_cfg\": {**FULL_AUG_CFG, \"gain\": False},\n",
    "        \"use_mixup\": True,\n",
    "    },\n",
    "    \"no_mixup\": {\n",
    "        \"aug_cfg\": FULL_AUG_CFG,\n",
    "        \"use_mixup\": False,\n",
    "    },\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \"no_aug\": {\n",
    "        \"aug_cfg\": {},      \n",
    "        \"use_mixup\": False,\n",
    "    },\n",
    "\n",
    "    \n",
    "    \"mixup_only\": {\n",
    "        \"aug_cfg\": {\n",
    "            \"time_mask\": False,\n",
    "            \"freq_mask\": False,\n",
    "            \"time_shift\": False,\n",
    "            \"gain\": False,\n",
    "        },\n",
    "        \"use_mixup\": True,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba03f77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running augmentation config: all_aug ===\n",
      "[aug_all_aug_blocks5_base64] Epoch 1/15 | Train Loss: 9.6731 Acc: 0.198 | Val Loss: 2.7912 Acc: 0.296 | F1: 0.305 UAR: 0.208\n",
      "[aug_all_aug_blocks5_base64] Epoch 2/15 | Train Loss: 2.4970 Acc: 0.213 | Val Loss: 7.0259 Acc: 0.048 | F1: 0.063 UAR: 0.183\n",
      "[aug_all_aug_blocks5_base64] Epoch 3/15 | Train Loss: 2.9495 Acc: 0.215 | Val Loss: 3.0683 Acc: 0.178 | F1: 0.166 UAR: 0.217\n",
      "[aug_all_aug_blocks5_base64] Epoch 4/15 | Train Loss: 2.5504 Acc: 0.213 | Val Loss: 4.0270 Acc: 0.079 | F1: 0.093 UAR: 0.219\n",
      "[aug_all_aug_blocks5_base64] Epoch 5/15 | Train Loss: 2.8584 Acc: 0.205 | Val Loss: 4.4925 Acc: 0.267 | F1: 0.254 UAR: 0.234\n",
      "[aug_all_aug_blocks5_base64] Epoch 6/15 | Train Loss: 2.2459 Acc: 0.231 | Val Loss: 1.4509 Acc: 0.318 | F1: 0.306 UAR: 0.231\n",
      "[aug_all_aug_blocks5_base64] Epoch 7/15 | Train Loss: 2.1179 Acc: 0.233 | Val Loss: 1.6644 Acc: 0.334 | F1: 0.345 UAR: 0.233\n",
      "[aug_all_aug_blocks5_base64] Epoch 8/15 | Train Loss: 2.0060 Acc: 0.220 | Val Loss: 2.6268 Acc: 0.135 | F1: 0.177 UAR: 0.230\n",
      "[aug_all_aug_blocks5_base64] Epoch 9/15 | Train Loss: 1.7527 Acc: 0.242 | Val Loss: 1.8296 Acc: 0.291 | F1: 0.258 UAR: 0.247\n",
      "[aug_all_aug_blocks5_base64] Epoch 10/15 | Train Loss: 1.6601 Acc: 0.273 | Val Loss: 1.7185 Acc: 0.168 | F1: 0.141 UAR: 0.218\n",
      "[aug_all_aug_blocks5_base64] Epoch 11/15 | Train Loss: 1.5982 Acc: 0.274 | Val Loss: 2.0555 Acc: 0.227 | F1: 0.185 UAR: 0.250\n",
      "[aug_all_aug_blocks5_base64] Epoch 12/15 | Train Loss: 1.6050 Acc: 0.277 | Val Loss: 1.7778 Acc: 0.240 | F1: 0.210 UAR: 0.243\n",
      "[aug_all_aug_blocks5_base64] Epoch 13/15 | Train Loss: 1.5309 Acc: 0.296 | Val Loss: 1.5918 Acc: 0.292 | F1: 0.309 UAR: 0.256\n",
      "[aug_all_aug_blocks5_base64] Epoch 14/15 | Train Loss: 1.4705 Acc: 0.297 | Val Loss: 1.6531 Acc: 0.251 | F1: 0.277 UAR: 0.260\n",
      "[aug_all_aug_blocks5_base64] Epoch 15/15 | Train Loss: 1.4870 Acc: 0.298 | Val Loss: 1.6301 Acc: 0.245 | F1: 0.284 UAR: 0.259\n",
      "üèÉ View run aug_all_aug_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4/runs/507787bc8ce049108ab4c2a95178befa\n",
      "üß™ View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4\n",
      "--> all_aug: best UAR=0.2603\n",
      "\n",
      "=== Running augmentation config: no_time_mask ===\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 1/15 | Train Loss: 8.5514 Acc: 0.205 | Val Loss: 2.5810 Acc: 0.201 | F1: 0.198 UAR: 0.236\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 2/15 | Train Loss: 2.6866 Acc: 0.231 | Val Loss: 4.1032 Acc: 0.105 | F1: 0.080 UAR: 0.229\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 3/15 | Train Loss: 2.3355 Acc: 0.219 | Val Loss: 2.1015 Acc: 0.248 | F1: 0.246 UAR: 0.236\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 4/15 | Train Loss: 2.6311 Acc: 0.218 | Val Loss: 2.0702 Acc: 0.367 | F1: 0.351 UAR: 0.234\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 5/15 | Train Loss: 2.4522 Acc: 0.217 | Val Loss: 2.4551 Acc: 0.254 | F1: 0.200 UAR: 0.244\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 6/15 | Train Loss: 2.1561 Acc: 0.235 | Val Loss: 2.1631 Acc: 0.206 | F1: 0.242 UAR: 0.241\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 7/15 | Train Loss: 1.9391 Acc: 0.235 | Val Loss: 2.5937 Acc: 0.224 | F1: 0.196 UAR: 0.235\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 8/15 | Train Loss: 1.7799 Acc: 0.247 | Val Loss: 2.0692 Acc: 0.223 | F1: 0.195 UAR: 0.236\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 9/15 | Train Loss: 1.7157 Acc: 0.260 | Val Loss: 1.5415 Acc: 0.278 | F1: 0.303 UAR: 0.248\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 10/15 | Train Loss: 1.5914 Acc: 0.277 | Val Loss: 2.1014 Acc: 0.103 | F1: 0.117 UAR: 0.232\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 11/15 | Train Loss: 1.5631 Acc: 0.264 | Val Loss: 1.8469 Acc: 0.148 | F1: 0.169 UAR: 0.239\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 12/15 | Train Loss: 1.5573 Acc: 0.289 | Val Loss: 1.7932 Acc: 0.237 | F1: 0.256 UAR: 0.267\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 13/15 | Train Loss: 1.5016 Acc: 0.271 | Val Loss: 2.0479 Acc: 0.095 | F1: 0.101 UAR: 0.212\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 14/15 | Train Loss: 1.5518 Acc: 0.293 | Val Loss: 2.0374 Acc: 0.119 | F1: 0.144 UAR: 0.223\n",
      "[aug_no_time_mask_blocks5_base64] Epoch 15/15 | Train Loss: 1.4537 Acc: 0.332 | Val Loss: 1.4415 Acc: 0.313 | F1: 0.337 UAR: 0.248\n",
      "üèÉ View run aug_no_time_mask_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4/runs/d93bf5bd13d340a1a2e83ea0fd3f7f09\n",
      "üß™ View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4\n",
      "--> no_time_mask: best UAR=0.2672\n",
      "\n",
      "=== Running augmentation config: no_freq_mask ===\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 1/15 | Train Loss: 8.5922 Acc: 0.202 | Val Loss: 3.8976 Acc: 0.167 | F1: 0.165 UAR: 0.211\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 2/15 | Train Loss: 2.8730 Acc: 0.209 | Val Loss: 3.2026 Acc: 0.239 | F1: 0.211 UAR: 0.230\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 3/15 | Train Loss: 2.6220 Acc: 0.218 | Val Loss: 2.9366 Acc: 0.269 | F1: 0.259 UAR: 0.234\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 4/15 | Train Loss: 2.3599 Acc: 0.238 | Val Loss: 1.8569 Acc: 0.348 | F1: 0.343 UAR: 0.222\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 5/15 | Train Loss: 2.0555 Acc: 0.223 | Val Loss: 3.2394 Acc: 0.179 | F1: 0.210 UAR: 0.240\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 6/15 | Train Loss: 1.8894 Acc: 0.243 | Val Loss: 3.3658 Acc: 0.032 | F1: 0.033 UAR: 0.209\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 7/15 | Train Loss: 1.8111 Acc: 0.246 | Val Loss: 2.0573 Acc: 0.266 | F1: 0.205 UAR: 0.242\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 8/15 | Train Loss: 1.6385 Acc: 0.252 | Val Loss: 1.9426 Acc: 0.222 | F1: 0.182 UAR: 0.226\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 9/15 | Train Loss: 1.6092 Acc: 0.262 | Val Loss: 1.5430 Acc: 0.265 | F1: 0.296 UAR: 0.224\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 10/15 | Train Loss: 1.6077 Acc: 0.260 | Val Loss: 1.8194 Acc: 0.247 | F1: 0.251 UAR: 0.255\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 11/15 | Train Loss: 1.5270 Acc: 0.294 | Val Loss: 1.9207 Acc: 0.224 | F1: 0.188 UAR: 0.252\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 12/15 | Train Loss: 1.4778 Acc: 0.296 | Val Loss: 1.5960 Acc: 0.248 | F1: 0.291 UAR: 0.244\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 13/15 | Train Loss: 1.4345 Acc: 0.268 | Val Loss: 1.6583 Acc: 0.312 | F1: 0.270 UAR: 0.251\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 14/15 | Train Loss: 1.4545 Acc: 0.302 | Val Loss: 1.6858 Acc: 0.212 | F1: 0.235 UAR: 0.222\n",
      "[aug_no_freq_mask_blocks5_base64] Epoch 15/15 | Train Loss: 1.3734 Acc: 0.354 | Val Loss: 1.4942 Acc: 0.298 | F1: 0.306 UAR: 0.249\n",
      "üèÉ View run aug_no_freq_mask_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4/runs/5371440795c34ae4aea2cdacaa2f2885\n",
      "üß™ View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4\n",
      "--> no_freq_mask: best UAR=0.2555\n",
      "\n",
      "=== Running augmentation config: no_time_shift ===\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 1/15 | Train Loss: 6.6817 Acc: 0.218 | Val Loss: 5.1785 Acc: 0.211 | F1: 0.253 UAR: 0.236\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 2/15 | Train Loss: 2.6648 Acc: 0.220 | Val Loss: 3.6175 Acc: 0.173 | F1: 0.193 UAR: 0.205\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 3/15 | Train Loss: 2.6803 Acc: 0.218 | Val Loss: 3.4792 Acc: 0.080 | F1: 0.111 UAR: 0.211\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 4/15 | Train Loss: 2.4866 Acc: 0.228 | Val Loss: 3.2938 Acc: 0.143 | F1: 0.145 UAR: 0.241\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 5/15 | Train Loss: 2.5858 Acc: 0.232 | Val Loss: 2.4366 Acc: 0.371 | F1: 0.360 UAR: 0.207\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 6/15 | Train Loss: 2.4307 Acc: 0.240 | Val Loss: 3.2985 Acc: 0.147 | F1: 0.167 UAR: 0.219\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 7/15 | Train Loss: 1.8718 Acc: 0.249 | Val Loss: 2.6299 Acc: 0.168 | F1: 0.140 UAR: 0.216\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 8/15 | Train Loss: 1.8691 Acc: 0.234 | Val Loss: 1.9017 Acc: 0.124 | F1: 0.144 UAR: 0.223\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 9/15 | Train Loss: 1.7448 Acc: 0.243 | Val Loss: 1.6700 Acc: 0.266 | F1: 0.278 UAR: 0.264\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 10/15 | Train Loss: 1.6693 Acc: 0.259 | Val Loss: 1.6405 Acc: 0.313 | F1: 0.347 UAR: 0.273\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 11/15 | Train Loss: 1.6499 Acc: 0.266 | Val Loss: 1.8838 Acc: 0.193 | F1: 0.216 UAR: 0.252\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 12/15 | Train Loss: 1.5161 Acc: 0.299 | Val Loss: 1.7077 Acc: 0.352 | F1: 0.299 UAR: 0.233\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 13/15 | Train Loss: 1.4457 Acc: 0.324 | Val Loss: 1.5385 Acc: 0.337 | F1: 0.360 UAR: 0.257\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 14/15 | Train Loss: 1.4609 Acc: 0.304 | Val Loss: 1.7754 Acc: 0.208 | F1: 0.222 UAR: 0.253\n",
      "[aug_no_time_shift_blocks5_base64] Epoch 15/15 | Train Loss: 1.4231 Acc: 0.345 | Val Loss: 1.4708 Acc: 0.295 | F1: 0.315 UAR: 0.257\n",
      "üèÉ View run aug_no_time_shift_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4/runs/41ea8189d4fa4a1e89219ff6ab24baff\n",
      "üß™ View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4\n",
      "--> no_time_shift: best UAR=0.2734\n",
      "\n",
      "=== Running augmentation config: no_gain ===\n",
      "[aug_no_gain_blocks5_base64] Epoch 1/15 | Train Loss: 7.2821 Acc: 0.207 | Val Loss: 3.3735 Acc: 0.158 | F1: 0.204 UAR: 0.209\n",
      "[aug_no_gain_blocks5_base64] Epoch 2/15 | Train Loss: 3.1228 Acc: 0.220 | Val Loss: 3.7876 Acc: 0.144 | F1: 0.176 UAR: 0.225\n",
      "[aug_no_gain_blocks5_base64] Epoch 3/15 | Train Loss: 2.6990 Acc: 0.219 | Val Loss: 2.5703 Acc: 0.134 | F1: 0.160 UAR: 0.224\n",
      "[aug_no_gain_blocks5_base64] Epoch 4/15 | Train Loss: 2.2378 Acc: 0.247 | Val Loss: 2.3628 Acc: 0.370 | F1: 0.229 UAR: 0.203\n",
      "[aug_no_gain_blocks5_base64] Epoch 5/15 | Train Loss: 2.3506 Acc: 0.230 | Val Loss: 4.4144 Acc: 0.193 | F1: 0.169 UAR: 0.253\n",
      "[aug_no_gain_blocks5_base64] Epoch 6/15 | Train Loss: 2.0512 Acc: 0.237 | Val Loss: 3.5254 Acc: 0.194 | F1: 0.199 UAR: 0.231\n",
      "[aug_no_gain_blocks5_base64] Epoch 7/15 | Train Loss: 2.0114 Acc: 0.255 | Val Loss: 1.8871 Acc: 0.345 | F1: 0.364 UAR: 0.234\n",
      "[aug_no_gain_blocks5_base64] Epoch 8/15 | Train Loss: 2.0918 Acc: 0.234 | Val Loss: 2.0304 Acc: 0.380 | F1: 0.305 UAR: 0.208\n",
      "[aug_no_gain_blocks5_base64] Epoch 9/15 | Train Loss: 1.8539 Acc: 0.260 | Val Loss: 2.1961 Acc: 0.362 | F1: 0.296 UAR: 0.223\n",
      "[aug_no_gain_blocks5_base64] Epoch 10/15 | Train Loss: 1.7569 Acc: 0.260 | Val Loss: 3.2143 Acc: 0.144 | F1: 0.123 UAR: 0.222\n",
      "[aug_no_gain_blocks5_base64] Epoch 11/15 | Train Loss: 1.6678 Acc: 0.277 | Val Loss: 2.1385 Acc: 0.304 | F1: 0.293 UAR: 0.257\n",
      "[aug_no_gain_blocks5_base64] Epoch 12/15 | Train Loss: 1.6173 Acc: 0.295 | Val Loss: 2.1974 Acc: 0.261 | F1: 0.251 UAR: 0.223\n",
      "[aug_no_gain_blocks5_base64] Epoch 13/15 | Train Loss: 1.4863 Acc: 0.304 | Val Loss: 1.8035 Acc: 0.229 | F1: 0.268 UAR: 0.231\n",
      "[aug_no_gain_blocks5_base64] Epoch 14/15 | Train Loss: 1.5092 Acc: 0.322 | Val Loss: 3.1816 Acc: 0.113 | F1: 0.102 UAR: 0.239\n",
      "[aug_no_gain_blocks5_base64] Epoch 15/15 | Train Loss: 1.4384 Acc: 0.292 | Val Loss: 1.7704 Acc: 0.289 | F1: 0.268 UAR: 0.232\n",
      "üèÉ View run aug_no_gain_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4/runs/97680cd9e3804fafa499d5a0be1e66c1\n",
      "üß™ View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4\n",
      "--> no_gain: best UAR=0.2567\n",
      "\n",
      "=== Running augmentation config: no_mixup ===\n",
      "[aug_no_mixup_blocks5_base64] Epoch 1/15 | Train Loss: 8.6081 Acc: 0.223 | Val Loss: 2.1398 Acc: 0.225 | F1: 0.251 UAR: 0.226\n",
      "[aug_no_mixup_blocks5_base64] Epoch 2/15 | Train Loss: 2.6202 Acc: 0.229 | Val Loss: 3.9900 Acc: 0.190 | F1: 0.179 UAR: 0.231\n",
      "[aug_no_mixup_blocks5_base64] Epoch 3/15 | Train Loss: 2.9531 Acc: 0.235 | Val Loss: 4.1929 Acc: 0.192 | F1: 0.182 UAR: 0.231\n",
      "[aug_no_mixup_blocks5_base64] Epoch 4/15 | Train Loss: 2.4912 Acc: 0.246 | Val Loss: 1.3286 Acc: 0.380 | F1: 0.326 UAR: 0.221\n",
      "[aug_no_mixup_blocks5_base64] Epoch 5/15 | Train Loss: 2.3957 Acc: 0.268 | Val Loss: 2.4559 Acc: 0.196 | F1: 0.204 UAR: 0.260\n",
      "[aug_no_mixup_blocks5_base64] Epoch 6/15 | Train Loss: 2.0822 Acc: 0.288 | Val Loss: 2.8503 Acc: 0.161 | F1: 0.170 UAR: 0.248\n",
      "[aug_no_mixup_blocks5_base64] Epoch 7/15 | Train Loss: 1.8487 Acc: 0.316 | Val Loss: 1.9594 Acc: 0.174 | F1: 0.170 UAR: 0.244\n",
      "[aug_no_mixup_blocks5_base64] Epoch 8/15 | Train Loss: 1.6952 Acc: 0.341 | Val Loss: 2.4519 Acc: 0.078 | F1: 0.075 UAR: 0.216\n",
      "[aug_no_mixup_blocks5_base64] Epoch 9/15 | Train Loss: 1.5470 Acc: 0.368 | Val Loss: 2.0455 Acc: 0.203 | F1: 0.211 UAR: 0.258\n",
      "[aug_no_mixup_blocks5_base64] Epoch 10/15 | Train Loss: 1.5562 Acc: 0.367 | Val Loss: 1.5033 Acc: 0.287 | F1: 0.295 UAR: 0.233\n",
      "[aug_no_mixup_blocks5_base64] Epoch 11/15 | Train Loss: 1.4195 Acc: 0.407 | Val Loss: 1.4476 Acc: 0.291 | F1: 0.296 UAR: 0.216\n",
      "[aug_no_mixup_blocks5_base64] Epoch 12/15 | Train Loss: 1.3515 Acc: 0.420 | Val Loss: 1.6307 Acc: 0.237 | F1: 0.264 UAR: 0.229\n",
      "[aug_no_mixup_blocks5_base64] Epoch 13/15 | Train Loss: 1.2839 Acc: 0.458 | Val Loss: 1.5839 Acc: 0.332 | F1: 0.277 UAR: 0.217\n",
      "[aug_no_mixup_blocks5_base64] Epoch 14/15 | Train Loss: 1.2654 Acc: 0.466 | Val Loss: 2.0797 Acc: 0.249 | F1: 0.195 UAR: 0.231\n",
      "[aug_no_mixup_blocks5_base64] Epoch 15/15 | Train Loss: 1.2706 Acc: 0.472 | Val Loss: 1.5110 Acc: 0.302 | F1: 0.326 UAR: 0.239\n",
      "üèÉ View run aug_no_mixup_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4/runs/7f2ca83db85e4abca2a26bdfbd1d2c1c\n",
      "üß™ View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4\n",
      "--> no_mixup: best UAR=0.2595\n",
      "\n",
      "=== Running augmentation config: no_aug ===\n",
      "[aug_no_aug_blocks5_base64] Epoch 1/15 | Train Loss: 4.7500 Acc: 0.242 | Val Loss: 4.3003 Acc: 0.168 | F1: 0.138 UAR: 0.197\n",
      "[aug_no_aug_blocks5_base64] Epoch 2/15 | Train Loss: 2.8666 Acc: 0.280 | Val Loss: 2.0227 Acc: 0.389 | F1: 0.343 UAR: 0.209\n",
      "[aug_no_aug_blocks5_base64] Epoch 3/15 | Train Loss: 2.4868 Acc: 0.313 | Val Loss: 3.7105 Acc: 0.209 | F1: 0.215 UAR: 0.214\n",
      "[aug_no_aug_blocks5_base64] Epoch 4/15 | Train Loss: 1.9251 Acc: 0.373 | Val Loss: 2.2698 Acc: 0.264 | F1: 0.297 UAR: 0.242\n",
      "[aug_no_aug_blocks5_base64] Epoch 5/15 | Train Loss: 1.6686 Acc: 0.423 | Val Loss: 2.9276 Acc: 0.394 | F1: 0.293 UAR: 0.213\n",
      "[aug_no_aug_blocks5_base64] Epoch 6/15 | Train Loss: 1.5455 Acc: 0.456 | Val Loss: 1.5752 Acc: 0.295 | F1: 0.328 UAR: 0.229\n",
      "[aug_no_aug_blocks5_base64] Epoch 7/15 | Train Loss: 1.2505 Acc: 0.514 | Val Loss: 1.8801 Acc: 0.263 | F1: 0.271 UAR: 0.235\n",
      "[aug_no_aug_blocks5_base64] Epoch 8/15 | Train Loss: 1.1346 Acc: 0.573 | Val Loss: 2.5673 Acc: 0.199 | F1: 0.157 UAR: 0.232\n",
      "[aug_no_aug_blocks5_base64] Epoch 9/15 | Train Loss: 1.1005 Acc: 0.573 | Val Loss: 2.2573 Acc: 0.230 | F1: 0.204 UAR: 0.227\n",
      "[aug_no_aug_blocks5_base64] Epoch 10/15 | Train Loss: 0.9796 Acc: 0.604 | Val Loss: 2.1393 Acc: 0.353 | F1: 0.218 UAR: 0.213\n",
      "[aug_no_aug_blocks5_base64] Epoch 11/15 | Train Loss: 0.9038 Acc: 0.652 | Val Loss: 2.0518 Acc: 0.217 | F1: 0.216 UAR: 0.224\n",
      "[aug_no_aug_blocks5_base64] Epoch 12/15 | Train Loss: 0.7994 Acc: 0.681 | Val Loss: 1.7667 Acc: 0.315 | F1: 0.327 UAR: 0.223\n",
      "[aug_no_aug_blocks5_base64] Epoch 13/15 | Train Loss: 0.7671 Acc: 0.714 | Val Loss: 2.0464 Acc: 0.422 | F1: 0.322 UAR: 0.211\n",
      "[aug_no_aug_blocks5_base64] Epoch 14/15 | Train Loss: 0.8313 Acc: 0.700 | Val Loss: 1.8053 Acc: 0.367 | F1: 0.376 UAR: 0.229\n",
      "[aug_no_aug_blocks5_base64] Epoch 15/15 | Train Loss: 0.6009 Acc: 0.770 | Val Loss: 2.0314 Acc: 0.356 | F1: 0.341 UAR: 0.227\n",
      "üèÉ View run aug_no_aug_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4/runs/72c262af83ad460893d1a75a5fd1e494\n",
      "üß™ View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4\n",
      "--> no_aug: best UAR=0.2422\n",
      "\n",
      "=== Running augmentation config: mixup_only ===\n",
      "[aug_mixup_only_blocks5_base64] Epoch 1/15 | Train Loss: 6.2947 Acc: 0.231 | Val Loss: 3.5451 Acc: 0.139 | F1: 0.144 UAR: 0.198\n",
      "[aug_mixup_only_blocks5_base64] Epoch 2/15 | Train Loss: 2.8298 Acc: 0.253 | Val Loss: 1.9447 Acc: 0.304 | F1: 0.287 UAR: 0.218\n",
      "[aug_mixup_only_blocks5_base64] Epoch 3/15 | Train Loss: 2.5811 Acc: 0.244 | Val Loss: 3.2911 Acc: 0.159 | F1: 0.120 UAR: 0.219\n",
      "[aug_mixup_only_blocks5_base64] Epoch 4/15 | Train Loss: 2.2584 Acc: 0.262 | Val Loss: 1.8346 Acc: 0.334 | F1: 0.295 UAR: 0.232\n",
      "[aug_mixup_only_blocks5_base64] Epoch 5/15 | Train Loss: 2.2265 Acc: 0.286 | Val Loss: 2.5471 Acc: 0.269 | F1: 0.232 UAR: 0.257\n",
      "[aug_mixup_only_blocks5_base64] Epoch 6/15 | Train Loss: 1.9376 Acc: 0.297 | Val Loss: 4.0318 Acc: 0.101 | F1: 0.100 UAR: 0.225\n",
      "[aug_mixup_only_blocks5_base64] Epoch 7/15 | Train Loss: 1.8244 Acc: 0.316 | Val Loss: 3.8515 Acc: 0.425 | F1: 0.302 UAR: 0.220\n",
      "[aug_mixup_only_blocks5_base64] Epoch 8/15 | Train Loss: 2.1690 Acc: 0.314 | Val Loss: 1.8331 Acc: 0.355 | F1: 0.348 UAR: 0.234\n",
      "[aug_mixup_only_blocks5_base64] Epoch 9/15 | Train Loss: 1.8347 Acc: 0.307 | Val Loss: 1.5868 Acc: 0.380 | F1: 0.359 UAR: 0.218\n",
      "[aug_mixup_only_blocks5_base64] Epoch 10/15 | Train Loss: 1.4845 Acc: 0.324 | Val Loss: 1.5139 Acc: 0.322 | F1: 0.328 UAR: 0.225\n",
      "[aug_mixup_only_blocks5_base64] Epoch 11/15 | Train Loss: 1.4893 Acc: 0.333 | Val Loss: 1.9897 Acc: 0.253 | F1: 0.212 UAR: 0.254\n",
      "[aug_mixup_only_blocks5_base64] Epoch 12/15 | Train Loss: 1.4966 Acc: 0.346 | Val Loss: 2.5511 Acc: 0.305 | F1: 0.233 UAR: 0.236\n",
      "[aug_mixup_only_blocks5_base64] Epoch 13/15 | Train Loss: 1.4206 Acc: 0.351 | Val Loss: 1.7871 Acc: 0.265 | F1: 0.297 UAR: 0.244\n",
      "[aug_mixup_only_blocks5_base64] Epoch 14/15 | Train Loss: 1.2939 Acc: 0.398 | Val Loss: 1.7671 Acc: 0.447 | F1: 0.319 UAR: 0.212\n",
      "[aug_mixup_only_blocks5_base64] Epoch 15/15 | Train Loss: 1.4142 Acc: 0.369 | Val Loss: 1.6287 Acc: 0.361 | F1: 0.364 UAR: 0.236\n",
      "üèÉ View run aug_mixup_only_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4/runs/f0c001dca0fd4279818365726090d223\n",
      "üß™ View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/4\n",
      "--> mixup_only: best UAR=0.2567\n",
      "\n",
      "*** Augmentation ablation summary ***\n",
      "all_aug         -> UAR=0.2603\n",
      "no_time_mask    -> UAR=0.2672\n",
      "no_freq_mask    -> UAR=0.2555\n",
      "no_time_shift   -> UAR=0.2734\n",
      "no_gain         -> UAR=0.2567\n",
      "no_mixup        -> UAR=0.2595\n",
      "no_aug          -> UAR=0.2422\n",
      "mixup_only      -> UAR=0.2567\n",
      "\n",
      ">>> Best augmentation config = no_time_shift with UAR=0.2734\n"
     ]
    }
   ],
   "source": [
    "aug_results = {}\n",
    "\n",
    "for name, cfg in AUG_EXPERIMENTS.items():\n",
    "    print(f\"\\n=== Running augmentation config: {name} ===\")\n",
    "\n",
    "    train_dataset = SpectrogramImageDataset(\n",
    "        train_image_paths,\n",
    "        train_labels_idx,\n",
    "        train=True,\n",
    "        aug_cfg=cfg[\"aug_cfg\"],\n",
    "    )\n",
    "\n",
    "    val_dataset = SpectrogramImageDataset(\n",
    "        val_image_paths,\n",
    "        val_labels_idx,\n",
    "        train=False,\n",
    "        aug_cfg=None,\n",
    "    )\n",
    "\n",
    "    run_name = f\"aug_{name}_blocks{NUM_BLOCKS}_base{BASE_CHANNELS}\"\n",
    "\n",
    "    model, best_uar = train_one_cnn_experiment(\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "        base_channels=BASE_CHANNELS,\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        num_classes=num_classes,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        lr=LR,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        epochs=EPOCHS,\n",
    "        run_name=run_name,\n",
    "        MODEL_DIR=\"saved_models\",\n",
    "        init_method=INIT_METHOD,\n",
    "        use_mixup=cfg[\"use_mixup\"],\n",
    "        mixup_alpha=0.4,\n",
    "        aug_cfg_name=name,\n",
    "        use_weighted_sampler=True,                 \n",
    "        sample_weights=sample_weights_tensor, \n",
    "    )\n",
    "\n",
    "    aug_results[name] = best_uar\n",
    "    print(f\"--> {name}: best UAR={best_uar:.4f}\")\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n*** Augmentation ablation summary ***\")\n",
    "for name, uar in aug_results.items():\n",
    "    print(f\"{name:15s} -> UAR={uar:.4f}\")\n",
    "\n",
    "best_cfg = max(aug_results, key=aug_results.get)\n",
    "print(f\"\\n>>> Best augmentation config = {best_cfg} with UAR={aug_results[best_cfg]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
