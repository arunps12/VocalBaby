{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1223ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one level up into project folder\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "#print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d308bf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import mlflow\n",
    "import dagshub\n",
    "\n",
    "from visioninfantnet.utils.ml_utils.metric.classification_metric import (\n",
    "    get_classification_score,\n",
    ")\n",
    "from visioninfantnet.exception.exception import VisionInfantNetException\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da2392c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as arunps12\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as arunps12\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"arunps12/VisionInfantNet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"arunps12/VisionInfantNet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository arunps12/VisionInfantNet initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository arunps12/VisionInfantNet initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run bright-bee-313 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/0/runs/5402700a169444218642667073e5f9a4\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "mlflow_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(mlflow_uri)\n",
    "dagshub.init(repo_owner='arunps12', repo_name='VisionInfantNet', mlflow=True)\n",
    "\n",
    "import mlflow\n",
    "with mlflow.start_run():\n",
    "  mlflow.log_param('parameter name', 'value')\n",
    "  mlflow.log_metric('metric name', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26084dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/itf-fi-ml/home/arunps/Projects/VisionInfantNet/artifacts/12_02_2025_10_27_46/data_transformation/spectrograms/train\n",
      "/itf-fi-ml/home/arunps/Projects/VisionInfantNet/artifacts/12_02_2025_10_27_46/data_transformation/spectrograms/valid\n",
      "/itf-fi-ml/home/arunps/Projects/VisionInfantNet/artifacts/12_02_2025_10_27_46/data_transformation/features/train_labels.npy\n",
      "/itf-fi-ml/home/arunps/Projects/VisionInfantNet/artifacts/12_02_2025_10_27_46/data_transformation/features/valid_labels.npy\n"
     ]
    }
   ],
   "source": [
    "#Paths and data loading helper\n",
    "\n",
    "ARTIFACT_ROOT = os.getenv(\"ARTIFACT_ROOT\")\n",
    "\n",
    "TRAIN_IMG_DIR = os.path.join(ARTIFACT_ROOT, \"data_transformation\", \"spectrograms\", \"train\")\n",
    "VAL_IMG_DIR   = os.path.join(ARTIFACT_ROOT, \"data_transformation\", \"spectrograms\", \"valid\")\n",
    "\n",
    "TRAIN_LABEL_NPY = os.path.join(ARTIFACT_ROOT, \"data_transformation\", \"features\", \"train_labels.npy\")\n",
    "VAL_LABEL_NPY   = os.path.join(ARTIFACT_ROOT, \"data_transformation\", \"features\", \"valid_labels.npy\")\n",
    "\n",
    "print(TRAIN_IMG_DIR)\n",
    "print(VAL_IMG_DIR)\n",
    "print(TRAIN_LABEL_NPY)\n",
    "print(VAL_LABEL_NPY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cb6a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600 3600\n",
      "3580 3580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load labels and image paths\n",
    "train_labels = np.load(TRAIN_LABEL_NPY)\n",
    "val_labels   = np.load(VAL_LABEL_NPY)\n",
    "\n",
    "train_image_paths = sorted(glob.glob(os.path.join(TRAIN_IMG_DIR, \"*.png\")))\n",
    "val_image_paths   = sorted(glob.glob(os.path.join(VAL_IMG_DIR, \"*.png\")))\n",
    "\n",
    "print(len(train_image_paths), len(train_labels))\n",
    "print(len(val_image_paths), len(val_labels))\n",
    "\n",
    "num_classes = len(np.unique(train_labels))\n",
    "num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ec1e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {np.str_('Canonical'): 0, np.str_('Crying'): 1, np.str_('Junk'): 2, np.str_('Laughing'): 3, np.str_('Non-canonical'): 4}\n",
      "num_classes: 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique_labels = sorted(set(train_labels) | set(val_labels))\n",
    "label_to_idx = {lab: i for i, lab in enumerate(unique_labels)}\n",
    "idx_to_label = {i: lab for lab, i in label_to_idx.items()}\n",
    "\n",
    "print(\"Label mapping:\", label_to_idx)\n",
    "num_classes = len(unique_labels)\n",
    "print(\"num_classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf2b5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "train_labels_idx = np.array([label_to_idx[l] for l in train_labels])\n",
    "val_labels_idx   = np.array([label_to_idx[l] for l in val_labels])\n",
    "print(train_labels_idx[:10])\n",
    "print(val_labels_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b8b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "class SpectrogramImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, train: bool = True):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "\n",
    "       \n",
    "        base_transforms = [\n",
    "            T.Resize((224, 224)),\n",
    "            T.ToTensor(),              # -> [1, H, W], values [0,1]\n",
    "        ]\n",
    "\n",
    "        self.transforms = T.Compose(base_transforms)\n",
    "\n",
    "        # ---- Model normalization ([-1,1]) ----\n",
    "        self.normalize = T.Normalize(\n",
    "            mean=[0.5, 0.5, 0.5],\n",
    "            std=[0.5, 0.5, 0.5],\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load grayscale PNG (0..255)\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "\n",
    "        # Apply transforms â†’ [1,224,224]\n",
    "        img = self.transforms(img)\n",
    "\n",
    "        # Convert grayscale -> RGB by repeating channels\n",
    "        img = img.repeat(3, 1, 1)  # [3,224,224]\n",
    "\n",
    "        # Normalize to [-1,1]\n",
    "        img = self.normalize(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2351141",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64  # override per experiment\n",
    "\n",
    "train_dataset = SpectrogramImageDataset(train_image_paths, train_labels_idx, train=True)\n",
    "val_dataset   = SpectrogramImageDataset(val_image_paths, val_labels_idx, train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5498ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # downsample by /2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class BaseCNNSpectrogram(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        base_channels: int = 32,\n",
    "        num_blocks: int = 3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        channels = [3] + [base_channels * (2 ** i) for i in range(num_blocks)]\n",
    "        conv_blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            conv_blocks.append(ConvBlock(channels[i], channels[i+1]))\n",
    "        self.conv = nn.Sequential(*conv_blocks)\n",
    "\n",
    "        last_channels = channels[-1]\n",
    "        spatial_size = 224 // (2 ** num_blocks)  # after MaxPool(2) num_blocks times\n",
    "        self.flatten_dim = last_channels * spatial_size * spatial_size\n",
    "\n",
    "        # Single DNN classification layer: Flatten -> Linear -> logits\n",
    "        self.fc = nn.Linear(self.flatten_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f8d6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "def init_cnn_weights(m, init_method: str):\n",
    "    \"\"\"\n",
    "    Apply a chosen initialization method to Conv and Linear layers.\n",
    "    \"\"\"\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        if init_method == \"kaiming_normal\":\n",
    "            init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "        elif init_method == \"kaiming_uniform\":\n",
    "            init.kaiming_uniform_(m.weight, nonlinearity=\"relu\")\n",
    "        elif init_method == \"xavier_normal\":\n",
    "            init.xavier_normal_(m.weight)\n",
    "        elif init_method == \"xavier_uniform\":\n",
    "            init.xavier_uniform_(m.weight)\n",
    "        elif init_method == \"orthogonal\":\n",
    "            init.orthogonal_(m.weight)\n",
    "        elif init_method == \"pytorch_default\":\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown init_method: {init_method}\")\n",
    "\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b64d9773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import mlflow.pytorch\n",
    "def train_one_cnn_experiment(\n",
    "    num_blocks: int,\n",
    "    base_channels: int,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    num_classes: int,\n",
    "    batch_size: int = 64,\n",
    "    lr: float = 1e-3,\n",
    "    weight_decay: float = 1e-4,\n",
    "    epochs: int = 15,\n",
    "    run_name: str = None,\n",
    "    MODEL_DIR: str = \"saved_models\",\n",
    "    init_method: str = \"pytorch_default\",\n",
    "):\n",
    "    # Dataloaders for training and validation # update loaders if batch_size changes\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    model = BaseCNNSpectrogram(\n",
    "        num_classes=num_classes,\n",
    "        base_channels=base_channels,\n",
    "        num_blocks=num_blocks,\n",
    "    ).to(device)\n",
    "\n",
    "    # Initialize weights\n",
    "    model.apply(lambda m: init_cnn_weights(m, init_method))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    if run_name is None:\n",
    "        run_name = f\"cnn_blocks{num_blocks}_base{base_channels}_{init_method}\"\n",
    "\n",
    "    best_val_uar = 0.0\n",
    "    best_epoch = -1\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_param(\"num_blocks\", num_blocks)\n",
    "        mlflow.log_param(\"base_channels\", base_channels)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "        mlflow.log_param(\"weight_decay\", weight_decay)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"model_type\", \"BaseCNN_flatten_linear\")\n",
    "        mlflow.log_param(\"init_method\", init_method)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # ---- train ----\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "\n",
    "            for imgs, labels in train_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item() * imgs.size(0)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                train_correct += (preds == labels).sum().item()\n",
    "                train_total += labels.size(0)\n",
    "\n",
    "            train_loss /= train_total\n",
    "            train_acc = train_correct / train_total\n",
    "\n",
    "            # ---- validation ----\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            all_true, all_pred = [], []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for imgs, labels in val_loader:\n",
    "                    imgs = imgs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    val_loss += loss.item() * imgs.size(0)\n",
    "                    preds = outputs.argmax(dim=1)\n",
    "\n",
    "                    val_correct += (preds == labels).sum().item()\n",
    "                    val_total += labels.size(0)\n",
    "\n",
    "                    all_true.extend(labels.cpu().numpy().tolist())\n",
    "                    all_pred.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "            val_loss /= val_total\n",
    "            val_acc = val_correct / val_total\n",
    "\n",
    "            # classification metrics\n",
    "            metrics = get_classification_score(\n",
    "                y_true=all_true,\n",
    "                y_pred=all_pred,\n",
    "                average=\"weighted\",\n",
    "            )\n",
    "\n",
    "            # Log metrics to MLflow\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "            mlflow.log_metric(\"train_acc\", train_acc, step=epoch)\n",
    "            mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "            mlflow.log_metric(\"val_acc\", val_acc, step=epoch)\n",
    "            mlflow.log_metric(\"val_f1\", metrics.f1_score, step=epoch)\n",
    "            mlflow.log_metric(\"val_precision\", metrics.precision_score, step=epoch)\n",
    "            mlflow.log_metric(\"val_recall\", metrics.recall_score, step=epoch)\n",
    "            mlflow.log_metric(\"val_uar\", metrics.uar, step=epoch)\n",
    "\n",
    "            if metrics.uar > best_val_uar:\n",
    "                best_val_uar = metrics.uar\n",
    "                best_epoch = epoch\n",
    "                os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "                model_path = os.path.join(\n",
    "                                            MODEL_DIR,\n",
    "                                                f\"best_model_blocks{num_blocks}_base{base_channels}_init_{init_method}.pt\"\n",
    "                                            )\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                mlflow.log_artifact(model_path)\n",
    "                #mlflow.pytorch.log_model(model, artifact_path=\"pytorch_model\")\n",
    "            print(\n",
    "                f\"[{run_name}] Epoch {epoch+1}/{epochs} | \"\n",
    "                f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.3f} | \"\n",
    "                f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.3f} | \"\n",
    "                f\"F1: {metrics.f1_score:.3f} UAR: {metrics.uar:.3f}\"\n",
    "            )\n",
    "\n",
    "        mlflow.log_metric(\"best_val_uar\", best_val_uar)\n",
    "        mlflow.log_param(\"best_epoch\", best_epoch)\n",
    "\n",
    "    return model, best_val_uar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bfac8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running base_channels=8, num_blocks=3 ===\n",
      "[base8_blocks3] Epoch 1/15 | Train Loss: 3.2883 Acc: 0.355 | Val Loss: 1.3928 Acc: 0.456 | F1: 0.304 UAR: 0.201\n",
      "[base8_blocks3] Epoch 2/15 | Train Loss: 1.2974 Acc: 0.420 | Val Loss: 1.5288 Acc: 0.378 | F1: 0.224 UAR: 0.204\n",
      "[base8_blocks3] Epoch 3/15 | Train Loss: 1.2679 Acc: 0.443 | Val Loss: 1.2628 Acc: 0.423 | F1: 0.382 UAR: 0.199\n",
      "[base8_blocks3] Epoch 4/15 | Train Loss: 1.1820 Acc: 0.470 | Val Loss: 1.7377 Acc: 0.254 | F1: 0.206 UAR: 0.239\n",
      "[base8_blocks3] Epoch 5/15 | Train Loss: 1.1249 Acc: 0.500 | Val Loss: 1.5035 Acc: 0.378 | F1: 0.234 UAR: 0.206\n",
      "[base8_blocks3] Epoch 6/15 | Train Loss: 1.0694 Acc: 0.518 | Val Loss: 1.3580 Acc: 0.404 | F1: 0.347 UAR: 0.203\n",
      "[base8_blocks3] Epoch 7/15 | Train Loss: 1.0331 Acc: 0.541 | Val Loss: 1.3205 Acc: 0.430 | F1: 0.371 UAR: 0.217\n",
      "[base8_blocks3] Epoch 8/15 | Train Loss: 0.9006 Acc: 0.604 | Val Loss: 1.3381 Acc: 0.396 | F1: 0.376 UAR: 0.218\n",
      "[base8_blocks3] Epoch 9/15 | Train Loss: 0.9031 Acc: 0.609 | Val Loss: 1.7863 Acc: 0.370 | F1: 0.259 UAR: 0.205\n",
      "[base8_blocks3] Epoch 10/15 | Train Loss: 0.7851 Acc: 0.656 | Val Loss: 1.4454 Acc: 0.402 | F1: 0.372 UAR: 0.216\n",
      "[base8_blocks3] Epoch 11/15 | Train Loss: 0.7171 Acc: 0.696 | Val Loss: 1.5291 Acc: 0.383 | F1: 0.364 UAR: 0.221\n",
      "[base8_blocks3] Epoch 12/15 | Train Loss: 0.6695 Acc: 0.720 | Val Loss: 1.9886 Acc: 0.361 | F1: 0.265 UAR: 0.212\n",
      "[base8_blocks3] Epoch 13/15 | Train Loss: 0.5051 Acc: 0.804 | Val Loss: 1.7434 Acc: 0.403 | F1: 0.382 UAR: 0.210\n",
      "[base8_blocks3] Epoch 14/15 | Train Loss: 0.4560 Acc: 0.814 | Val Loss: 1.9918 Acc: 0.406 | F1: 0.384 UAR: 0.212\n",
      "[base8_blocks3] Epoch 15/15 | Train Loss: 0.3317 Acc: 0.880 | Val Loss: 2.5809 Acc: 0.444 | F1: 0.356 UAR: 0.208\n",
      "ðŸƒ View run base8_blocks3 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/1/runs/ecf0f242912541c6b9e63cb4c88c92fc\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/1\n",
      "--> base_channels=8: best UAR=0.2386\n",
      "\n",
      "=== Running base_channels=16, num_blocks=3 ===\n",
      "[base16_blocks3] Epoch 1/15 | Train Loss: 7.1990 Acc: 0.355 | Val Loss: 1.6544 Acc: 0.347 | F1: 0.352 UAR: 0.225\n",
      "[base16_blocks3] Epoch 2/15 | Train Loss: 1.5372 Acc: 0.409 | Val Loss: 2.1960 Acc: 0.331 | F1: 0.221 UAR: 0.223\n",
      "[base16_blocks3] Epoch 3/15 | Train Loss: 1.5220 Acc: 0.424 | Val Loss: 1.4776 Acc: 0.388 | F1: 0.379 UAR: 0.216\n",
      "[base16_blocks3] Epoch 4/15 | Train Loss: 1.5258 Acc: 0.425 | Val Loss: 1.7322 Acc: 0.402 | F1: 0.374 UAR: 0.197\n",
      "[base16_blocks3] Epoch 5/15 | Train Loss: 1.5068 Acc: 0.440 | Val Loss: 1.6169 Acc: 0.445 | F1: 0.365 UAR: 0.206\n",
      "[base16_blocks3] Epoch 6/15 | Train Loss: 1.2487 Acc: 0.492 | Val Loss: 1.9031 Acc: 0.377 | F1: 0.251 UAR: 0.196\n",
      "[base16_blocks3] Epoch 7/15 | Train Loss: 1.3604 Acc: 0.484 | Val Loss: 2.2878 Acc: 0.364 | F1: 0.224 UAR: 0.206\n",
      "[base16_blocks3] Epoch 8/15 | Train Loss: 1.1981 Acc: 0.520 | Val Loss: 1.5960 Acc: 0.403 | F1: 0.363 UAR: 0.203\n",
      "[base16_blocks3] Epoch 9/15 | Train Loss: 1.1074 Acc: 0.554 | Val Loss: 1.5937 Acc: 0.370 | F1: 0.368 UAR: 0.220\n",
      "[base16_blocks3] Epoch 10/15 | Train Loss: 0.9299 Acc: 0.607 | Val Loss: 1.5604 Acc: 0.412 | F1: 0.388 UAR: 0.209\n",
      "[base16_blocks3] Epoch 11/15 | Train Loss: 0.8764 Acc: 0.636 | Val Loss: 2.0503 Acc: 0.385 | F1: 0.302 UAR: 0.205\n",
      "[base16_blocks3] Epoch 12/15 | Train Loss: 0.8779 Acc: 0.629 | Val Loss: 1.7949 Acc: 0.393 | F1: 0.341 UAR: 0.216\n",
      "[base16_blocks3] Epoch 13/15 | Train Loss: 0.7456 Acc: 0.694 | Val Loss: 2.0162 Acc: 0.367 | F1: 0.329 UAR: 0.223\n",
      "[base16_blocks3] Epoch 14/15 | Train Loss: 0.8453 Acc: 0.675 | Val Loss: 1.7807 Acc: 0.360 | F1: 0.343 UAR: 0.211\n",
      "[base16_blocks3] Epoch 15/15 | Train Loss: 0.6828 Acc: 0.725 | Val Loss: 2.1169 Acc: 0.341 | F1: 0.296 UAR: 0.211\n",
      "ðŸƒ View run base16_blocks3 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/1/runs/ec17b49e68a44972a2a427681d3224dd\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/1\n",
      "--> base_channels=16: best UAR=0.2246\n",
      "\n",
      "=== Running base_channels=32, num_blocks=3 ===\n",
      "[base32_blocks3] Epoch 1/15 | Train Loss: 9.9412 Acc: 0.356 | Val Loss: 3.5401 Acc: 0.329 | F1: 0.228 UAR: 0.204\n",
      "[base32_blocks3] Epoch 2/15 | Train Loss: 3.7287 Acc: 0.364 | Val Loss: 2.6631 Acc: 0.335 | F1: 0.294 UAR: 0.220\n",
      "[base32_blocks3] Epoch 3/15 | Train Loss: 2.4793 Acc: 0.404 | Val Loss: 2.3827 Acc: 0.375 | F1: 0.243 UAR: 0.204\n",
      "[base32_blocks3] Epoch 4/15 | Train Loss: 3.3370 Acc: 0.399 | Val Loss: 3.3261 Acc: 0.149 | F1: 0.176 UAR: 0.214\n",
      "[base32_blocks3] Epoch 5/15 | Train Loss: 2.1321 Acc: 0.419 | Val Loss: 2.2115 Acc: 0.417 | F1: 0.388 UAR: 0.210\n",
      "[base32_blocks3] Epoch 6/15 | Train Loss: 2.0346 Acc: 0.451 | Val Loss: 3.0290 Acc: 0.375 | F1: 0.224 UAR: 0.203\n",
      "[base32_blocks3] Epoch 7/15 | Train Loss: 1.6160 Acc: 0.477 | Val Loss: 1.8784 Acc: 0.402 | F1: 0.343 UAR: 0.204\n",
      "[base32_blocks3] Epoch 8/15 | Train Loss: 1.3280 Acc: 0.506 | Val Loss: 1.7328 Acc: 0.413 | F1: 0.393 UAR: 0.225\n",
      "[base32_blocks3] Epoch 9/15 | Train Loss: 1.3844 Acc: 0.507 | Val Loss: 1.6364 Acc: 0.374 | F1: 0.374 UAR: 0.217\n",
      "[base32_blocks3] Epoch 10/15 | Train Loss: 1.1112 Acc: 0.556 | Val Loss: 2.2189 Acc: 0.368 | F1: 0.234 UAR: 0.205\n",
      "[base32_blocks3] Epoch 11/15 | Train Loss: 1.2029 Acc: 0.546 | Val Loss: 2.6288 Acc: 0.384 | F1: 0.247 UAR: 0.200\n",
      "[base32_blocks3] Epoch 12/15 | Train Loss: 1.1832 Acc: 0.549 | Val Loss: 1.7415 Acc: 0.395 | F1: 0.363 UAR: 0.219\n",
      "[base32_blocks3] Epoch 13/15 | Train Loss: 0.9246 Acc: 0.615 | Val Loss: 1.9183 Acc: 0.337 | F1: 0.313 UAR: 0.213\n",
      "[base32_blocks3] Epoch 14/15 | Train Loss: 0.8717 Acc: 0.637 | Val Loss: 1.8786 Acc: 0.409 | F1: 0.377 UAR: 0.212\n",
      "[base32_blocks3] Epoch 15/15 | Train Loss: 0.9115 Acc: 0.639 | Val Loss: 1.7936 Acc: 0.403 | F1: 0.384 UAR: 0.207\n",
      "ðŸƒ View run base32_blocks3 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/1/runs/9e00a27b25c847b09df2bac0f0aababe\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/1\n",
      "--> base_channels=32: best UAR=0.2251\n",
      "\n",
      "=== Running base_channels=64, num_blocks=3 ===\n",
      "[base64_blocks3] Epoch 1/15 | Train Loss: 21.2656 Acc: 0.346 | Val Loss: 5.2415 Acc: 0.317 | F1: 0.290 UAR: 0.237\n",
      "[base64_blocks3] Epoch 2/15 | Train Loss: 8.5190 Acc: 0.356 | Val Loss: 4.3305 Acc: 0.366 | F1: 0.321 UAR: 0.234\n",
      "[base64_blocks3] Epoch 3/15 | Train Loss: 4.6291 Acc: 0.384 | Val Loss: 4.0164 Acc: 0.309 | F1: 0.325 UAR: 0.216\n",
      "[base64_blocks3] Epoch 4/15 | Train Loss: 3.5264 Acc: 0.407 | Val Loss: 3.6638 Acc: 0.324 | F1: 0.324 UAR: 0.223\n",
      "[base64_blocks3] Epoch 5/15 | Train Loss: 4.4416 Acc: 0.405 | Val Loss: 4.3514 Acc: 0.249 | F1: 0.208 UAR: 0.234\n",
      "[base64_blocks3] Epoch 6/15 | Train Loss: 5.0685 Acc: 0.407 | Val Loss: 3.6123 Acc: 0.381 | F1: 0.244 UAR: 0.201\n",
      "[base64_blocks3] Epoch 7/15 | Train Loss: 2.5898 Acc: 0.446 | Val Loss: 2.5323 Acc: 0.413 | F1: 0.382 UAR: 0.203\n",
      "[base64_blocks3] Epoch 8/15 | Train Loss: 1.7158 Acc: 0.483 | Val Loss: 1.9813 Acc: 0.407 | F1: 0.327 UAR: 0.207\n",
      "[base64_blocks3] Epoch 9/15 | Train Loss: 1.4088 Acc: 0.509 | Val Loss: 1.8903 Acc: 0.381 | F1: 0.329 UAR: 0.201\n",
      "[base64_blocks3] Epoch 10/15 | Train Loss: 1.2628 Acc: 0.548 | Val Loss: 1.7130 Acc: 0.366 | F1: 0.371 UAR: 0.224\n",
      "[base64_blocks3] Epoch 11/15 | Train Loss: 1.0679 Acc: 0.571 | Val Loss: 1.7849 Acc: 0.382 | F1: 0.337 UAR: 0.209\n",
      "[base64_blocks3] Epoch 12/15 | Train Loss: 1.1978 Acc: 0.545 | Val Loss: 1.6914 Acc: 0.406 | F1: 0.382 UAR: 0.200\n",
      "[base64_blocks3] Epoch 13/15 | Train Loss: 1.0941 Acc: 0.572 | Val Loss: 2.2069 Acc: 0.355 | F1: 0.291 UAR: 0.207\n",
      "[base64_blocks3] Epoch 14/15 | Train Loss: 0.9486 Acc: 0.607 | Val Loss: 1.8435 Acc: 0.346 | F1: 0.340 UAR: 0.218\n",
      "[base64_blocks3] Epoch 15/15 | Train Loss: 0.8528 Acc: 0.648 | Val Loss: 1.9041 Acc: 0.434 | F1: 0.350 UAR: 0.204\n",
      "ðŸƒ View run base64_blocks3 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/1/runs/86d3b8194254492085dfcce5977c4454\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/1\n",
      "--> base_channels=64: best UAR=0.2370\n"
     ]
    }
   ],
   "source": [
    "# ---- MLflow Experiment 1: base_channels sweep ----\n",
    "mlflow.set_experiment(\"cnn_exp1_base_channels\")\n",
    "\n",
    "BASE_CHANNEL_LIST = [8, 16, 32, 64]\n",
    "FIXED_NUM_BLOCKS = 3\n",
    "\n",
    "base_channel_results = {}\n",
    "\n",
    "for bc in BASE_CHANNEL_LIST:\n",
    "    print(f\"\\n=== Running base_channels={bc}, num_blocks={FIXED_NUM_BLOCKS} ===\")\n",
    "    run_name = f\"base{bc}_blocks{FIXED_NUM_BLOCKS}\"\n",
    "\n",
    "    model, best_uar = train_one_cnn_experiment(\n",
    "        num_blocks=FIXED_NUM_BLOCKS,\n",
    "        base_channels=bc,\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        num_classes=num_classes,\n",
    "        batch_size=64,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "        epochs=15,\n",
    "        run_name=run_name,\n",
    "    )\n",
    "\n",
    "    base_channel_results[bc] = best_uar\n",
    "    print(f\"--> base_channels={bc}: best UAR={best_uar:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98b32ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running num_blocks=2, base_channels=64 ===\n",
      "[blocks2_base64] Epoch 1/15 | Train Loss: 44.5425 Acc: 0.347 | Val Loss: 13.9489 Acc: 0.377 | F1: 0.235 UAR: 0.200\n",
      "[blocks2_base64] Epoch 2/15 | Train Loss: 15.4631 Acc: 0.367 | Val Loss: 13.3996 Acc: 0.429 | F1: 0.375 UAR: 0.206\n",
      "[blocks2_base64] Epoch 3/15 | Train Loss: 15.0422 Acc: 0.389 | Val Loss: 16.0260 Acc: 0.282 | F1: 0.211 UAR: 0.217\n",
      "[blocks2_base64] Epoch 4/15 | Train Loss: 8.9733 Acc: 0.429 | Val Loss: 16.4752 Acc: 0.357 | F1: 0.265 UAR: 0.206\n",
      "[blocks2_base64] Epoch 5/15 | Train Loss: 9.8473 Acc: 0.441 | Val Loss: 9.6741 Acc: 0.432 | F1: 0.398 UAR: 0.210\n",
      "[blocks2_base64] Epoch 6/15 | Train Loss: 5.7654 Acc: 0.493 | Val Loss: 6.7503 Acc: 0.435 | F1: 0.378 UAR: 0.207\n",
      "[blocks2_base64] Epoch 7/15 | Train Loss: 4.3215 Acc: 0.536 | Val Loss: 12.2780 Acc: 0.315 | F1: 0.274 UAR: 0.215\n",
      "[blocks2_base64] Epoch 8/15 | Train Loss: 4.7584 Acc: 0.506 | Val Loss: 6.6528 Acc: 0.413 | F1: 0.387 UAR: 0.206\n",
      "[blocks2_base64] Epoch 9/15 | Train Loss: 6.3848 Acc: 0.511 | Val Loss: 8.7274 Acc: 0.389 | F1: 0.371 UAR: 0.210\n",
      "[blocks2_base64] Epoch 10/15 | Train Loss: 3.0840 Acc: 0.585 | Val Loss: 7.3508 Acc: 0.363 | F1: 0.284 UAR: 0.210\n",
      "[blocks2_base64] Epoch 11/15 | Train Loss: 2.7031 Acc: 0.610 | Val Loss: 6.2165 Acc: 0.323 | F1: 0.316 UAR: 0.216\n",
      "[blocks2_base64] Epoch 12/15 | Train Loss: 2.5857 Acc: 0.599 | Val Loss: 5.8704 Acc: 0.351 | F1: 0.339 UAR: 0.218\n",
      "[blocks2_base64] Epoch 13/15 | Train Loss: 1.4477 Acc: 0.708 | Val Loss: 4.9165 Acc: 0.359 | F1: 0.363 UAR: 0.217\n",
      "[blocks2_base64] Epoch 14/15 | Train Loss: 1.2798 Acc: 0.713 | Val Loss: 8.9658 Acc: 0.376 | F1: 0.246 UAR: 0.210\n",
      "[blocks2_base64] Epoch 15/15 | Train Loss: 1.8705 Acc: 0.657 | Val Loss: 5.8376 Acc: 0.397 | F1: 0.376 UAR: 0.206\n",
      "ðŸƒ View run blocks2_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/2/runs/6d4252905a02420180222a839ded7c69\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/2\n",
      "--> num_blocks=2: best UAR=0.2182\n",
      "\n",
      "=== Running num_blocks=3, base_channels=64 ===\n",
      "[blocks3_base64] Epoch 1/15 | Train Loss: 18.4766 Acc: 0.335 | Val Loss: 8.6679 Acc: 0.375 | F1: 0.207 UAR: 0.198\n",
      "[blocks3_base64] Epoch 2/15 | Train Loss: 7.5643 Acc: 0.371 | Val Loss: 7.5629 Acc: 0.453 | F1: 0.324 UAR: 0.200\n",
      "[blocks3_base64] Epoch 3/15 | Train Loss: 7.6595 Acc: 0.400 | Val Loss: 5.1035 Acc: 0.228 | F1: 0.211 UAR: 0.215\n",
      "[blocks3_base64] Epoch 4/15 | Train Loss: 5.4457 Acc: 0.380 | Val Loss: 4.5438 Acc: 0.427 | F1: 0.354 UAR: 0.217\n",
      "[blocks3_base64] Epoch 5/15 | Train Loss: 3.4911 Acc: 0.411 | Val Loss: 3.1059 Acc: 0.404 | F1: 0.378 UAR: 0.210\n",
      "[blocks3_base64] Epoch 6/15 | Train Loss: 2.8598 Acc: 0.421 | Val Loss: 2.2173 Acc: 0.416 | F1: 0.392 UAR: 0.213\n",
      "[blocks3_base64] Epoch 7/15 | Train Loss: 1.9416 Acc: 0.484 | Val Loss: 3.8111 Acc: 0.424 | F1: 0.296 UAR: 0.206\n",
      "[blocks3_base64] Epoch 8/15 | Train Loss: 3.0581 Acc: 0.426 | Val Loss: 3.2051 Acc: 0.392 | F1: 0.296 UAR: 0.201\n",
      "[blocks3_base64] Epoch 9/15 | Train Loss: 2.8641 Acc: 0.436 | Val Loss: 3.2683 Acc: 0.456 | F1: 0.299 UAR: 0.206\n",
      "[blocks3_base64] Epoch 10/15 | Train Loss: 1.6523 Acc: 0.497 | Val Loss: 2.0431 Acc: 0.394 | F1: 0.353 UAR: 0.217\n",
      "[blocks3_base64] Epoch 11/15 | Train Loss: 1.3463 Acc: 0.535 | Val Loss: 2.0605 Acc: 0.395 | F1: 0.323 UAR: 0.209\n",
      "[blocks3_base64] Epoch 12/15 | Train Loss: 1.1949 Acc: 0.561 | Val Loss: 2.1384 Acc: 0.409 | F1: 0.333 UAR: 0.215\n",
      "[blocks3_base64] Epoch 13/15 | Train Loss: 1.1235 Acc: 0.567 | Val Loss: 2.0112 Acc: 0.398 | F1: 0.327 UAR: 0.211\n",
      "[blocks3_base64] Epoch 14/15 | Train Loss: 0.9963 Acc: 0.599 | Val Loss: 2.0268 Acc: 0.312 | F1: 0.312 UAR: 0.219\n",
      "[blocks3_base64] Epoch 15/15 | Train Loss: 0.9797 Acc: 0.616 | Val Loss: 1.9657 Acc: 0.359 | F1: 0.373 UAR: 0.236\n",
      "ðŸƒ View run blocks3_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/2/runs/30192621cd794b6695d122afc280af1f\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/2\n",
      "--> num_blocks=3: best UAR=0.2358\n",
      "\n",
      "=== Running num_blocks=4, base_channels=64 ===\n",
      "[blocks4_base64] Epoch 1/15 | Train Loss: 11.7999 Acc: 0.351 | Val Loss: 3.3929 Acc: 0.358 | F1: 0.234 UAR: 0.208\n",
      "[blocks4_base64] Epoch 2/15 | Train Loss: 3.9254 Acc: 0.360 | Val Loss: 5.6545 Acc: 0.117 | F1: 0.052 UAR: 0.199\n",
      "[blocks4_base64] Epoch 3/15 | Train Loss: 3.5669 Acc: 0.368 | Val Loss: 2.0141 Acc: 0.429 | F1: 0.387 UAR: 0.210\n",
      "[blocks4_base64] Epoch 4/15 | Train Loss: 1.9450 Acc: 0.402 | Val Loss: 2.3803 Acc: 0.172 | F1: 0.178 UAR: 0.216\n",
      "[blocks4_base64] Epoch 5/15 | Train Loss: 2.2880 Acc: 0.387 | Val Loss: 2.5429 Acc: 0.394 | F1: 0.370 UAR: 0.211\n",
      "[blocks4_base64] Epoch 6/15 | Train Loss: 1.9071 Acc: 0.417 | Val Loss: 1.8834 Acc: 0.389 | F1: 0.352 UAR: 0.192\n",
      "[blocks4_base64] Epoch 7/15 | Train Loss: 2.0759 Acc: 0.399 | Val Loss: 2.1223 Acc: 0.364 | F1: 0.336 UAR: 0.222\n",
      "[blocks4_base64] Epoch 8/15 | Train Loss: 1.7010 Acc: 0.436 | Val Loss: 1.6235 Acc: 0.456 | F1: 0.348 UAR: 0.203\n",
      "[blocks4_base64] Epoch 9/15 | Train Loss: 1.6191 Acc: 0.446 | Val Loss: 1.7166 Acc: 0.332 | F1: 0.316 UAR: 0.225\n",
      "[blocks4_base64] Epoch 10/15 | Train Loss: 1.3815 Acc: 0.456 | Val Loss: 2.6692 Acc: 0.329 | F1: 0.206 UAR: 0.213\n",
      "[blocks4_base64] Epoch 11/15 | Train Loss: 1.5061 Acc: 0.458 | Val Loss: 1.6886 Acc: 0.430 | F1: 0.350 UAR: 0.202\n",
      "[blocks4_base64] Epoch 12/15 | Train Loss: 1.3604 Acc: 0.471 | Val Loss: 1.9321 Acc: 0.376 | F1: 0.237 UAR: 0.202\n",
      "[blocks4_base64] Epoch 13/15 | Train Loss: 1.2937 Acc: 0.487 | Val Loss: 1.6673 Acc: 0.394 | F1: 0.347 UAR: 0.213\n",
      "[blocks4_base64] Epoch 14/15 | Train Loss: 1.1946 Acc: 0.521 | Val Loss: 1.6843 Acc: 0.392 | F1: 0.340 UAR: 0.196\n",
      "[blocks4_base64] Epoch 15/15 | Train Loss: 1.2708 Acc: 0.490 | Val Loss: 1.6473 Acc: 0.396 | F1: 0.372 UAR: 0.218\n",
      "ðŸƒ View run blocks4_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/2/runs/9ea19dc5f0c146a6be5dc60c2604b242\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/2\n",
      "--> num_blocks=4: best UAR=0.2254\n",
      "\n",
      "=== Running num_blocks=5, base_channels=64 ===\n",
      "[blocks5_base64] Epoch 1/15 | Train Loss: 5.2987 Acc: 0.353 | Val Loss: 1.5364 Acc: 0.396 | F1: 0.349 UAR: 0.197\n",
      "[blocks5_base64] Epoch 2/15 | Train Loss: 1.5863 Acc: 0.386 | Val Loss: 2.0652 Acc: 0.184 | F1: 0.176 UAR: 0.226\n",
      "[blocks5_base64] Epoch 3/15 | Train Loss: 1.6297 Acc: 0.398 | Val Loss: 1.8179 Acc: 0.330 | F1: 0.285 UAR: 0.225\n",
      "[blocks5_base64] Epoch 4/15 | Train Loss: 1.3996 Acc: 0.388 | Val Loss: 1.3758 Acc: 0.457 | F1: 0.291 UAR: 0.200\n",
      "[blocks5_base64] Epoch 5/15 | Train Loss: 1.3926 Acc: 0.405 | Val Loss: 1.4436 Acc: 0.389 | F1: 0.314 UAR: 0.228\n",
      "[blocks5_base64] Epoch 6/15 | Train Loss: 1.3854 Acc: 0.421 | Val Loss: 1.2198 Acc: 0.433 | F1: 0.399 UAR: 0.208\n",
      "[blocks5_base64] Epoch 7/15 | Train Loss: 1.3262 Acc: 0.415 | Val Loss: 1.3930 Acc: 0.434 | F1: 0.305 UAR: 0.210\n",
      "[blocks5_base64] Epoch 8/15 | Train Loss: 1.3044 Acc: 0.426 | Val Loss: 1.3808 Acc: 0.458 | F1: 0.322 UAR: 0.202\n",
      "[blocks5_base64] Epoch 9/15 | Train Loss: 1.2562 Acc: 0.446 | Val Loss: 1.7318 Acc: 0.379 | F1: 0.227 UAR: 0.207\n",
      "[blocks5_base64] Epoch 10/15 | Train Loss: 1.2819 Acc: 0.431 | Val Loss: 1.2357 Acc: 0.429 | F1: 0.402 UAR: 0.213\n",
      "[blocks5_base64] Epoch 11/15 | Train Loss: 1.1812 Acc: 0.479 | Val Loss: 1.4075 Acc: 0.316 | F1: 0.328 UAR: 0.240\n",
      "[blocks5_base64] Epoch 12/15 | Train Loss: 1.2004 Acc: 0.474 | Val Loss: 1.4235 Acc: 0.381 | F1: 0.244 UAR: 0.199\n",
      "[blocks5_base64] Epoch 13/15 | Train Loss: 1.1933 Acc: 0.457 | Val Loss: 1.3171 Acc: 0.385 | F1: 0.376 UAR: 0.228\n",
      "[blocks5_base64] Epoch 14/15 | Train Loss: 1.1271 Acc: 0.491 | Val Loss: 1.5749 Acc: 0.377 | F1: 0.226 UAR: 0.202\n",
      "[blocks5_base64] Epoch 15/15 | Train Loss: 1.2111 Acc: 0.457 | Val Loss: 1.2403 Acc: 0.398 | F1: 0.370 UAR: 0.204\n",
      "ðŸƒ View run blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/2/runs/7fe99a7938224f809a5c173bc57c1243\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/2\n",
      "--> num_blocks=5: best UAR=0.2401\n",
      "\n",
      "=== Running num_blocks=6, base_channels=64 ===\n",
      "[blocks6_base64] Epoch 1/15 | Train Loss: 2.6566 Acc: 0.386 | Val Loss: 1.3221 Acc: 0.392 | F1: 0.349 UAR: 0.219\n",
      "[blocks6_base64] Epoch 2/15 | Train Loss: 1.4385 Acc: 0.393 | Val Loss: 1.4638 Acc: 0.349 | F1: 0.205 UAR: 0.202\n",
      "[blocks6_base64] Epoch 3/15 | Train Loss: 1.3477 Acc: 0.381 | Val Loss: 1.3169 Acc: 0.458 | F1: 0.288 UAR: 0.200\n",
      "[blocks6_base64] Epoch 4/15 | Train Loss: 1.3296 Acc: 0.413 | Val Loss: 1.2725 Acc: 0.459 | F1: 0.321 UAR: 0.205\n",
      "[blocks6_base64] Epoch 5/15 | Train Loss: 1.2537 Acc: 0.414 | Val Loss: 1.3639 Acc: 0.458 | F1: 0.288 UAR: 0.200\n",
      "[blocks6_base64] Epoch 6/15 | Train Loss: 1.2600 Acc: 0.425 | Val Loss: 1.3436 Acc: 0.392 | F1: 0.299 UAR: 0.233\n",
      "[blocks6_base64] Epoch 7/15 | Train Loss: 1.2254 Acc: 0.448 | Val Loss: 1.1888 Acc: 0.427 | F1: 0.385 UAR: 0.217\n",
      "[blocks6_base64] Epoch 8/15 | Train Loss: 1.2045 Acc: 0.447 | Val Loss: 1.2079 Acc: 0.455 | F1: 0.408 UAR: 0.215\n",
      "[blocks6_base64] Epoch 9/15 | Train Loss: 1.2079 Acc: 0.443 | Val Loss: 1.2578 Acc: 0.377 | F1: 0.255 UAR: 0.214\n",
      "[blocks6_base64] Epoch 10/15 | Train Loss: 1.1500 Acc: 0.474 | Val Loss: 1.2556 Acc: 0.446 | F1: 0.383 UAR: 0.205\n",
      "[blocks6_base64] Epoch 11/15 | Train Loss: 1.1426 Acc: 0.485 | Val Loss: 1.2443 Acc: 0.385 | F1: 0.305 UAR: 0.207\n",
      "[blocks6_base64] Epoch 12/15 | Train Loss: 1.1187 Acc: 0.504 | Val Loss: 1.3144 Acc: 0.413 | F1: 0.383 UAR: 0.203\n",
      "[blocks6_base64] Epoch 13/15 | Train Loss: 1.0637 Acc: 0.540 | Val Loss: 1.4060 Acc: 0.358 | F1: 0.360 UAR: 0.229\n",
      "[blocks6_base64] Epoch 14/15 | Train Loss: 1.0184 Acc: 0.568 | Val Loss: 1.3072 Acc: 0.446 | F1: 0.370 UAR: 0.202\n",
      "[blocks6_base64] Epoch 15/15 | Train Loss: 0.9495 Acc: 0.588 | Val Loss: 1.4920 Acc: 0.404 | F1: 0.341 UAR: 0.204\n",
      "ðŸƒ View run blocks6_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/2/runs/d61abca54bde44d4a976d697fdb2ab3d\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/2\n",
      "--> num_blocks=6: best UAR=0.2327\n",
      "\n",
      "*** Best num_blocks = 5 with UAR=0.2401 ***\n"
     ]
    }
   ],
   "source": [
    "# ---- MLflow Experiment 2: num_blocks sweep ----\n",
    "mlflow.set_experiment(\"cnn_exp2_num_blocks\")\n",
    "\n",
    "best_base_channels = 64 # best from exp1 \n",
    "NUM_BLOCKS_LIST = [2, 3, 4, 5, 6]\n",
    "\n",
    "blocks_results = {}\n",
    "\n",
    "for nb in NUM_BLOCKS_LIST:\n",
    "    print(f\"\\n=== Running num_blocks={nb}, base_channels={best_base_channels} ===\")\n",
    "    run_name = f\"blocks{nb}_base{best_base_channels}\"\n",
    "\n",
    "    model, best_uar = train_one_cnn_experiment(\n",
    "        num_blocks=nb,\n",
    "        base_channels=best_base_channels,   \n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        num_classes=num_classes,\n",
    "        batch_size=64,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "        epochs=15,\n",
    "        run_name=run_name,\n",
    "    )\n",
    "\n",
    "    blocks_results[nb] = best_uar\n",
    "    print(f\"--> num_blocks={nb}: best UAR={best_uar:.4f}\")\n",
    "\n",
    "# pick best num_blocks\n",
    "best_num_blocks = max(blocks_results, key=blocks_results.get)\n",
    "best_blocks_uar = blocks_results[best_num_blocks]\n",
    "print(f\"\\n*** Best num_blocks = {best_num_blocks} with UAR={best_blocks_uar:.4f} ***\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ac33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/02 15:26:23 INFO mlflow.tracking.fluent: Experiment with name 'cnn_exp3_init_methods' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running init_method=pytorch_default, num_blocks=5, base_channels=64 ===\n",
      "[init_pytorch_default_blocks5_base64] Epoch 1/15 | Train Loss: 5.6753 Acc: 0.346 | Val Loss: 2.2290 Acc: 0.255 | F1: 0.281 UAR: 0.217\n",
      "[init_pytorch_default_blocks5_base64] Epoch 2/15 | Train Loss: 2.0815 Acc: 0.359 | Val Loss: 2.1406 Acc: 0.280 | F1: 0.296 UAR: 0.223\n",
      "[init_pytorch_default_blocks5_base64] Epoch 3/15 | Train Loss: 1.8716 Acc: 0.368 | Val Loss: 1.4183 Acc: 0.338 | F1: 0.353 UAR: 0.234\n",
      "[init_pytorch_default_blocks5_base64] Epoch 4/15 | Train Loss: 1.4672 Acc: 0.389 | Val Loss: 1.4271 Acc: 0.458 | F1: 0.292 UAR: 0.202\n",
      "[init_pytorch_default_blocks5_base64] Epoch 5/15 | Train Loss: 1.3393 Acc: 0.407 | Val Loss: 1.2845 Acc: 0.455 | F1: 0.323 UAR: 0.201\n",
      "[init_pytorch_default_blocks5_base64] Epoch 6/15 | Train Loss: 1.2971 Acc: 0.412 | Val Loss: 1.3094 Acc: 0.359 | F1: 0.354 UAR: 0.227\n",
      "[init_pytorch_default_blocks5_base64] Epoch 7/15 | Train Loss: 1.3232 Acc: 0.423 | Val Loss: 1.3830 Acc: 0.458 | F1: 0.291 UAR: 0.200\n",
      "[init_pytorch_default_blocks5_base64] Epoch 8/15 | Train Loss: 1.2825 Acc: 0.440 | Val Loss: 1.3156 Acc: 0.445 | F1: 0.367 UAR: 0.201\n",
      "[init_pytorch_default_blocks5_base64] Epoch 9/15 | Train Loss: 1.3050 Acc: 0.423 | Val Loss: 1.3327 Acc: 0.379 | F1: 0.294 UAR: 0.201\n",
      "[init_pytorch_default_blocks5_base64] Epoch 10/15 | Train Loss: 1.2330 Acc: 0.447 | Val Loss: 1.2004 Acc: 0.455 | F1: 0.384 UAR: 0.207\n",
      "[init_pytorch_default_blocks5_base64] Epoch 11/15 | Train Loss: 1.1981 Acc: 0.459 | Val Loss: 1.2267 Acc: 0.386 | F1: 0.372 UAR: 0.217\n",
      "[init_pytorch_default_blocks5_base64] Epoch 12/15 | Train Loss: 1.1982 Acc: 0.474 | Val Loss: 1.3483 Acc: 0.417 | F1: 0.328 UAR: 0.219\n",
      "[init_pytorch_default_blocks5_base64] Epoch 13/15 | Train Loss: 1.1913 Acc: 0.465 | Val Loss: 1.6696 Acc: 0.236 | F1: 0.242 UAR: 0.251\n",
      "[init_pytorch_default_blocks5_base64] Epoch 14/15 | Train Loss: 1.2356 Acc: 0.451 | Val Loss: 1.2763 Acc: 0.397 | F1: 0.383 UAR: 0.209\n",
      "[init_pytorch_default_blocks5_base64] Epoch 15/15 | Train Loss: 1.1177 Acc: 0.503 | Val Loss: 1.3100 Acc: 0.389 | F1: 0.360 UAR: 0.220\n",
      "ðŸƒ View run init_pytorch_default_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/3/runs/b41fb659f28a4b4e933a65a3e19d63cf\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/3\n",
      "--> init_method=pytorch_default: best UAR=0.2511\n",
      "\n",
      "=== Running init_method=kaiming_normal, num_blocks=5, base_channels=64 ===\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 1/15 | Train Loss: 6.8991 Acc: 0.349 | Val Loss: 2.9428 Acc: 0.158 | F1: 0.145 UAR: 0.212\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 2/15 | Train Loss: 2.6807 Acc: 0.348 | Val Loss: 1.4459 Acc: 0.444 | F1: 0.377 UAR: 0.208\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 3/15 | Train Loss: 1.6540 Acc: 0.406 | Val Loss: 2.0294 Acc: 0.456 | F1: 0.300 UAR: 0.206\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 4/15 | Train Loss: 1.8674 Acc: 0.376 | Val Loss: 1.6638 Acc: 0.455 | F1: 0.334 UAR: 0.202\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 5/15 | Train Loss: 1.5574 Acc: 0.408 | Val Loss: 1.8663 Acc: 0.452 | F1: 0.289 UAR: 0.202\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 6/15 | Train Loss: 1.4958 Acc: 0.414 | Val Loss: 1.8037 Acc: 0.392 | F1: 0.292 UAR: 0.222\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 7/15 | Train Loss: 1.4632 Acc: 0.421 | Val Loss: 1.3987 Acc: 0.378 | F1: 0.374 UAR: 0.212\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 8/15 | Train Loss: 1.3788 Acc: 0.420 | Val Loss: 1.7283 Acc: 0.382 | F1: 0.217 UAR: 0.201\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 9/15 | Train Loss: 1.3382 Acc: 0.434 | Val Loss: 1.2924 Acc: 0.392 | F1: 0.349 UAR: 0.202\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 10/15 | Train Loss: 1.3617 Acc: 0.434 | Val Loss: 1.4997 Acc: 0.434 | F1: 0.312 UAR: 0.213\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 11/15 | Train Loss: 1.2703 Acc: 0.458 | Val Loss: 1.2877 Acc: 0.461 | F1: 0.344 UAR: 0.210\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 12/15 | Train Loss: 1.1606 Acc: 0.481 | Val Loss: 1.3860 Acc: 0.368 | F1: 0.361 UAR: 0.225\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 13/15 | Train Loss: 1.1691 Acc: 0.481 | Val Loss: 1.4336 Acc: 0.402 | F1: 0.363 UAR: 0.199\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 14/15 | Train Loss: 1.1584 Acc: 0.493 | Val Loss: 1.6253 Acc: 0.360 | F1: 0.269 UAR: 0.203\n",
      "[init_kaiming_normal_blocks5_base64] Epoch 15/15 | Train Loss: 1.1267 Acc: 0.511 | Val Loss: 1.3549 Acc: 0.427 | F1: 0.397 UAR: 0.212\n",
      "ðŸƒ View run init_kaiming_normal_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/3/runs/391f1bcd60f541ccb8be555f0ed177d1\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/3\n",
      "--> init_method=kaiming_normal: best UAR=0.2250\n",
      "\n",
      "=== Running init_method=kaiming_uniform, num_blocks=5, base_channels=64 ===\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 1/15 | Train Loss: 9.9962 Acc: 0.358 | Val Loss: 1.8732 Acc: 0.453 | F1: 0.344 UAR: 0.203\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 2/15 | Train Loss: 1.8190 Acc: 0.387 | Val Loss: 1.5977 Acc: 0.361 | F1: 0.371 UAR: 0.225\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 3/15 | Train Loss: 1.7133 Acc: 0.391 | Val Loss: 1.4559 Acc: 0.333 | F1: 0.337 UAR: 0.213\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 4/15 | Train Loss: 1.5653 Acc: 0.409 | Val Loss: 1.8841 Acc: 0.207 | F1: 0.197 UAR: 0.219\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 5/15 | Train Loss: 1.5521 Acc: 0.397 | Val Loss: 1.5092 Acc: 0.408 | F1: 0.375 UAR: 0.208\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 6/15 | Train Loss: 1.4603 Acc: 0.428 | Val Loss: 1.9817 Acc: 0.311 | F1: 0.262 UAR: 0.204\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 7/15 | Train Loss: 1.4923 Acc: 0.396 | Val Loss: 1.3969 Acc: 0.407 | F1: 0.377 UAR: 0.203\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 8/15 | Train Loss: 1.3263 Acc: 0.449 | Val Loss: 1.4932 Acc: 0.325 | F1: 0.318 UAR: 0.218\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 9/15 | Train Loss: 1.3823 Acc: 0.437 | Val Loss: 1.6960 Acc: 0.361 | F1: 0.292 UAR: 0.215\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 10/15 | Train Loss: 1.2816 Acc: 0.471 | Val Loss: 1.5198 Acc: 0.365 | F1: 0.342 UAR: 0.223\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 11/15 | Train Loss: 1.2843 Acc: 0.457 | Val Loss: 1.2939 Acc: 0.388 | F1: 0.370 UAR: 0.218\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 12/15 | Train Loss: 1.1879 Acc: 0.491 | Val Loss: 1.5543 Acc: 0.309 | F1: 0.254 UAR: 0.228\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 13/15 | Train Loss: 1.1818 Acc: 0.484 | Val Loss: 1.3802 Acc: 0.414 | F1: 0.380 UAR: 0.201\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 14/15 | Train Loss: 1.2038 Acc: 0.494 | Val Loss: 1.4736 Acc: 0.385 | F1: 0.275 UAR: 0.199\n",
      "[init_kaiming_uniform_blocks5_base64] Epoch 15/15 | Train Loss: 1.1762 Acc: 0.491 | Val Loss: 1.5447 Acc: 0.380 | F1: 0.267 UAR: 0.197\n",
      "ðŸƒ View run init_kaiming_uniform_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/3/runs/e0b047a2d48844749418c6e9f806f820\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/3\n",
      "--> init_method=kaiming_uniform: best UAR=0.2282\n",
      "\n",
      "=== Running init_method=xavier_normal, num_blocks=5, base_channels=64 ===\n",
      "[init_xavier_normal_blocks5_base64] Epoch 1/15 | Train Loss: 9.6383 Acc: 0.349 | Val Loss: 2.0625 Acc: 0.322 | F1: 0.326 UAR: 0.218\n",
      "[init_xavier_normal_blocks5_base64] Epoch 2/15 | Train Loss: 2.4296 Acc: 0.379 | Val Loss: 2.7456 Acc: 0.421 | F1: 0.371 UAR: 0.204\n",
      "[init_xavier_normal_blocks5_base64] Epoch 3/15 | Train Loss: 2.3355 Acc: 0.381 | Val Loss: 1.8716 Acc: 0.403 | F1: 0.359 UAR: 0.211\n",
      "[init_xavier_normal_blocks5_base64] Epoch 4/15 | Train Loss: 2.2365 Acc: 0.375 | Val Loss: 3.2503 Acc: 0.299 | F1: 0.277 UAR: 0.218\n",
      "[init_xavier_normal_blocks5_base64] Epoch 5/15 | Train Loss: 2.6893 Acc: 0.369 | Val Loss: 1.7561 Acc: 0.438 | F1: 0.320 UAR: 0.208\n",
      "[init_xavier_normal_blocks5_base64] Epoch 6/15 | Train Loss: 2.1374 Acc: 0.386 | Val Loss: 2.3617 Acc: 0.307 | F1: 0.318 UAR: 0.228\n",
      "[init_xavier_normal_blocks5_base64] Epoch 7/15 | Train Loss: 1.8337 Acc: 0.392 | Val Loss: 1.5719 Acc: 0.410 | F1: 0.376 UAR: 0.196\n",
      "[init_xavier_normal_blocks5_base64] Epoch 8/15 | Train Loss: 1.8486 Acc: 0.393 | Val Loss: 2.1088 Acc: 0.372 | F1: 0.228 UAR: 0.200\n",
      "[init_xavier_normal_blocks5_base64] Epoch 9/15 | Train Loss: 1.7725 Acc: 0.406 | Val Loss: 2.2004 Acc: 0.378 | F1: 0.229 UAR: 0.200\n",
      "[init_xavier_normal_blocks5_base64] Epoch 10/15 | Train Loss: 1.5487 Acc: 0.430 | Val Loss: 1.7838 Acc: 0.358 | F1: 0.317 UAR: 0.207\n",
      "[init_xavier_normal_blocks5_base64] Epoch 11/15 | Train Loss: 1.4730 Acc: 0.456 | Val Loss: 2.3294 Acc: 0.378 | F1: 0.215 UAR: 0.203\n",
      "[init_xavier_normal_blocks5_base64] Epoch 12/15 | Train Loss: 1.3448 Acc: 0.461 | Val Loss: 1.5735 Acc: 0.414 | F1: 0.380 UAR: 0.197\n",
      "[init_xavier_normal_blocks5_base64] Epoch 13/15 | Train Loss: 1.2718 Acc: 0.477 | Val Loss: 1.9880 Acc: 0.382 | F1: 0.238 UAR: 0.203\n",
      "[init_xavier_normal_blocks5_base64] Epoch 14/15 | Train Loss: 1.2290 Acc: 0.495 | Val Loss: 1.7016 Acc: 0.327 | F1: 0.320 UAR: 0.210\n",
      "[init_xavier_normal_blocks5_base64] Epoch 15/15 | Train Loss: 1.1844 Acc: 0.510 | Val Loss: 1.5223 Acc: 0.373 | F1: 0.280 UAR: 0.199\n",
      "ðŸƒ View run init_xavier_normal_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/3/runs/d99a016f2dc542879018e65017495189\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/3\n",
      "--> init_method=xavier_normal: best UAR=0.2284\n",
      "\n",
      "=== Running init_method=xavier_uniform, num_blocks=5, base_channels=64 ===\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 1/15 | Train Loss: 8.0423 Acc: 0.354 | Val Loss: 4.0417 Acc: 0.233 | F1: 0.267 UAR: 0.197\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 2/15 | Train Loss: 2.3194 Acc: 0.370 | Val Loss: 1.7307 Acc: 0.461 | F1: 0.377 UAR: 0.208\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 3/15 | Train Loss: 2.2250 Acc: 0.374 | Val Loss: 3.7047 Acc: 0.352 | F1: 0.337 UAR: 0.197\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 4/15 | Train Loss: 2.4277 Acc: 0.385 | Val Loss: 4.2045 Acc: 0.449 | F1: 0.365 UAR: 0.204\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 5/15 | Train Loss: 2.8744 Acc: 0.369 | Val Loss: 2.3941 Acc: 0.451 | F1: 0.293 UAR: 0.199\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 6/15 | Train Loss: 2.0058 Acc: 0.403 | Val Loss: 2.2395 Acc: 0.378 | F1: 0.216 UAR: 0.199\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 7/15 | Train Loss: 2.2804 Acc: 0.390 | Val Loss: 2.1645 Acc: 0.333 | F1: 0.287 UAR: 0.228\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 8/15 | Train Loss: 1.9086 Acc: 0.396 | Val Loss: 1.8355 Acc: 0.304 | F1: 0.306 UAR: 0.241\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 9/15 | Train Loss: 1.5435 Acc: 0.426 | Val Loss: 2.3098 Acc: 0.421 | F1: 0.385 UAR: 0.199\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 10/15 | Train Loss: 1.7928 Acc: 0.413 | Val Loss: 1.8955 Acc: 0.374 | F1: 0.281 UAR: 0.211\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 11/15 | Train Loss: 1.5417 Acc: 0.452 | Val Loss: 1.3883 Acc: 0.394 | F1: 0.342 UAR: 0.197\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 12/15 | Train Loss: 1.2740 Acc: 0.481 | Val Loss: 1.7993 Acc: 0.382 | F1: 0.385 UAR: 0.222\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 13/15 | Train Loss: 1.2619 Acc: 0.498 | Val Loss: 1.6420 Acc: 0.451 | F1: 0.396 UAR: 0.208\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 14/15 | Train Loss: 1.1953 Acc: 0.516 | Val Loss: 1.5370 Acc: 0.399 | F1: 0.393 UAR: 0.218\n",
      "[init_xavier_uniform_blocks5_base64] Epoch 15/15 | Train Loss: 1.1842 Acc: 0.541 | Val Loss: 1.6018 Acc: 0.413 | F1: 0.379 UAR: 0.201\n",
      "ðŸƒ View run init_xavier_uniform_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/3/runs/1dea355ab0f646959414264a294874e7\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/3\n",
      "--> init_method=xavier_uniform: best UAR=0.2413\n",
      "\n",
      "=== Running init_method=orthogonal, num_blocks=5, base_channels=64 ===\n",
      "[init_orthogonal_blocks5_base64] Epoch 1/15 | Train Loss: 5.3704 Acc: 0.361 | Val Loss: 3.3658 Acc: 0.442 | F1: 0.318 UAR: 0.202\n",
      "[init_orthogonal_blocks5_base64] Epoch 2/15 | Train Loss: 2.4142 Acc: 0.368 | Val Loss: 1.6947 Acc: 0.380 | F1: 0.333 UAR: 0.201\n",
      "[init_orthogonal_blocks5_base64] Epoch 3/15 | Train Loss: 1.9760 Acc: 0.377 | Val Loss: 1.6432 Acc: 0.456 | F1: 0.364 UAR: 0.207\n",
      "[init_orthogonal_blocks5_base64] Epoch 4/15 | Train Loss: 1.9665 Acc: 0.375 | Val Loss: 1.9641 Acc: 0.457 | F1: 0.298 UAR: 0.200\n",
      "[init_orthogonal_blocks5_base64] Epoch 5/15 | Train Loss: 1.6692 Acc: 0.398 | Val Loss: 1.3343 Acc: 0.453 | F1: 0.301 UAR: 0.199\n",
      "[init_orthogonal_blocks5_base64] Epoch 6/15 | Train Loss: 1.4166 Acc: 0.418 | Val Loss: 1.3623 Acc: 0.382 | F1: 0.306 UAR: 0.202\n",
      "[init_orthogonal_blocks5_base64] Epoch 7/15 | Train Loss: 1.3246 Acc: 0.427 | Val Loss: 1.6004 Acc: 0.360 | F1: 0.236 UAR: 0.220\n",
      "[init_orthogonal_blocks5_base64] Epoch 8/15 | Train Loss: 1.3064 Acc: 0.424 | Val Loss: 1.3128 Acc: 0.452 | F1: 0.324 UAR: 0.205\n",
      "[init_orthogonal_blocks5_base64] Epoch 9/15 | Train Loss: 1.2485 Acc: 0.449 | Val Loss: 1.3823 Acc: 0.411 | F1: 0.380 UAR: 0.235\n",
      "[init_orthogonal_blocks5_base64] Epoch 10/15 | Train Loss: 1.2373 Acc: 0.457 | Val Loss: 1.4095 Acc: 0.417 | F1: 0.384 UAR: 0.203\n",
      "[init_orthogonal_blocks5_base64] Epoch 11/15 | Train Loss: 1.1794 Acc: 0.468 | Val Loss: 1.3450 Acc: 0.378 | F1: 0.282 UAR: 0.204\n",
      "[init_orthogonal_blocks5_base64] Epoch 12/15 | Train Loss: 1.2215 Acc: 0.457 | Val Loss: 1.2993 Acc: 0.394 | F1: 0.319 UAR: 0.200\n",
      "[init_orthogonal_blocks5_base64] Epoch 13/15 | Train Loss: 1.1586 Acc: 0.507 | Val Loss: 1.4187 Acc: 0.383 | F1: 0.317 UAR: 0.199\n",
      "[init_orthogonal_blocks5_base64] Epoch 14/15 | Train Loss: 1.1001 Acc: 0.507 | Val Loss: 1.3026 Acc: 0.448 | F1: 0.384 UAR: 0.213\n",
      "[init_orthogonal_blocks5_base64] Epoch 15/15 | Train Loss: 1.0567 Acc: 0.536 | Val Loss: 1.6360 Acc: 0.376 | F1: 0.223 UAR: 0.201\n",
      "ðŸƒ View run init_orthogonal_blocks5_base64 at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/3/runs/64aa9a2e38da4ca58b2f73b82fbb8f02\n",
      "ðŸ§ª View experiment at: https://dagshub.com/arunps12/VisionInfantNet.mlflow/#/experiments/3\n",
      "--> init_method=orthogonal: best UAR=0.2348\n",
      "\n",
      "*** Initialization summary ***\n",
      "pytorch_default  -> UAR=0.2511\n",
      "kaiming_normal   -> UAR=0.2250\n",
      "kaiming_uniform  -> UAR=0.2282\n",
      "xavier_normal    -> UAR=0.2284\n",
      "xavier_uniform   -> UAR=0.2413\n",
      "orthogonal       -> UAR=0.2348\n",
      "\n",
      ">>> Best init_method = pytorch_default with UAR=0.2511\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ---- MLflow Experiment 3: initialization sweep ----\n",
    "mlflow.set_experiment(\"cnn_exp3_init_methods\")\n",
    "\n",
    "INIT_METHODS = [\n",
    "    \"pytorch_default\",\n",
    "    \"kaiming_normal\",\n",
    "    \"kaiming_uniform\",\n",
    "    \"xavier_normal\",\n",
    "    \"xavier_uniform\",\n",
    "    \"orthogonal\",\n",
    "]\n",
    "\n",
    "init_results = {}\n",
    "\n",
    "for init_method in INIT_METHODS:\n",
    "    print(f\"\\n=== Running init_method={init_method}, num_blocks=5, base_channels=64 ===\")\n",
    "    run_name = f\"init_{init_method}_blocks5_base64\"\n",
    "\n",
    "    model, best_uar = train_one_cnn_experiment(\n",
    "        num_blocks=5,                  # from previous best\n",
    "        base_channels=64,              # from previous best\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        num_classes=num_classes,\n",
    "        batch_size=64,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "        epochs=15,\n",
    "        run_name=run_name,\n",
    "        init_method=init_method,\n",
    "    )\n",
    "\n",
    "    init_results[init_method] = best_uar\n",
    "    print(f\"--> init_method={init_method}: best UAR={best_uar:.4f}\")\n",
    "\n",
    "best_init = max(init_results, key=init_results.get)\n",
    "print(\"\\n*** Initialization summary ***\")\n",
    "for k, v in init_results.items():\n",
    "    print(f\"{k:16s} -> UAR={v:.4f}\")\n",
    "\n",
    "print(f\"\\n>>> Best init_method = {best_init} with UAR={init_results[best_init]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
